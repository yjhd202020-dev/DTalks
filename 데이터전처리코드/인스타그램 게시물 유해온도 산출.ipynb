{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d75888d-a727-4dfd-ae23-d4f0119fa436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저장 완료 → C:/Users/asia/Desktop/파이널프로젝트/03_데이터전처리/reels_temperature.csv\n",
      " reels_index  temperature\n",
      "           1         36.5\n",
      "           2         36.5\n",
      "           3         36.5\n",
      "           4         36.5\n",
      "           5         36.5\n",
      "           6         36.5\n",
      "           7         36.6\n",
      "           8         36.5\n",
      "           9         36.5\n",
      "          10         36.5\n"
     ]
    }
   ],
   "source": [
    "# ==== Reels 유해온도 산출(1% → +0.035℃, 36.5~40.0) : 단일 셀 실행용 ====\n",
    "import os, json, re, unicodedata\n",
    "import pandas as pd\n",
    "\n",
    "# 0) 경로 설정 (여기만 네 환경에 맞게 바꿔!)\n",
    "INPUT_JSONL    = \"C:/Users/asia/Desktop/파이널프로젝트/03_데이터전처리/138개 릴스 댓글정보.jsonl\"   # 수집해둔 JSONL\n",
    "BAD_WORDS_TXT  = \"C:/workspaces/FinalProject/bad_words.txt\"            # 네가 만든 욕설 리스트\n",
    "OUTPUT_CSV     = \"C:/Users/asia/Desktop/파이널프로젝트/03_데이터전처리/reels_temperature.csv\"     # 결과 저장 경로\n",
    "\n",
    "# 1) 유틸\n",
    "def load_badwords(path: str):\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"bad_words.txt 파일을 못 찾음: {path}\")\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        words = [w.strip() for w in f if w.strip() and not w.startswith(\"#\")]\n",
    "    return sorted(set(words))\n",
    "\n",
    "def compile_patterns(badwords):\n",
    "    pats = []\n",
    "    for w in badwords:\n",
    "        # 문자 사이에 특수문자/공백 끼워넣기(우회) 대응: '시발' -> 시[\\W_]*발\n",
    "        esc = \"\".join([re.escape(ch) + r\"[\\W_]*\" for ch in w])\n",
    "        pats.append(re.compile(esc, re.IGNORECASE))\n",
    "    return pats\n",
    "\n",
    "def normalize(txt: str) -> str:\n",
    "    t = unicodedata.normalize(\"NFKC\", str(txt)).lower()\n",
    "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
    "    return t\n",
    "\n",
    "def is_toxic(text: str, patterns) -> bool:\n",
    "    t = normalize(text)\n",
    "    return any(p.search(t) for p in patterns)\n",
    "\n",
    "def pct_round_1(n_toxic: int, n_total: int) -> int:\n",
    "    if n_total <= 0: return 0\n",
    "    return int(round((n_toxic / n_total) * 100))  # 1% 단위 반올림\n",
    "\n",
    "def temp_from_pct(pct: int) -> float:\n",
    "    temp = 36.5 + pct * 0.035\n",
    "    return round(min(temp, 40.0), 1)  # 상한 40.0, 소수1자리\n",
    "\n",
    "# 2) 데이터 로드 (JSONL: 각 줄이 {\"reels_index\":…, \"text\":…})\n",
    "records = []\n",
    "with open(INPUT_JSONL, \"r\", encoding=\"utf-8\") as f:\n",
    "    for lineno, line in enumerate(f, 1):\n",
    "        line = line.strip()\n",
    "        if not line: \n",
    "            continue\n",
    "        try:\n",
    "            obj = json.loads(line)\n",
    "        except Exception:\n",
    "            # 혹시 파이썬 dict 문자열로 저장된 경우 대응\n",
    "            obj = eval(line)\n",
    "        rid  = obj.get(\"reels_index\") or obj.get(\"reel_index\") or obj.get(\"id\")\n",
    "        text = obj.get(\"text\") or obj.get(\"comment\") or \"\"\n",
    "        if rid is None:\n",
    "            print(f\"[경고] {lineno}번째 줄: reels_index 없음 → 스킵\")\n",
    "            continue\n",
    "        records.append({\"reels_index\": rid, \"text\": str(text)})\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "if df.empty:\n",
    "    raise ValueError(\"입력 데이터가 비어있음. JSONL 구조(reels_index, text) 확인 필요\")\n",
    "\n",
    "# 3) bad_words 로드/컴파일\n",
    "badwords = load_badwords(BAD_WORDS_TXT)\n",
    "patterns = compile_patterns(badwords)\n",
    "\n",
    "# 4) reels_index별 집계 → 유해온도\n",
    "grouped = df.groupby(\"reels_index\")[\"text\"].apply(list).reset_index(name=\"comments\")\n",
    "rows = []\n",
    "for _, row in grouped.iterrows():\n",
    "    comments = row[\"comments\"]\n",
    "    flags = [is_toxic(t, patterns) for t in comments]\n",
    "    n_total, n_toxic = len(comments), sum(flags)\n",
    "    pct  = pct_round_1(n_toxic, n_total)\n",
    "    temp = temp_from_pct(pct)\n",
    "    rows.append({\"reels_index\": row[\"reels_index\"], \"temperature\": temp})\n",
    "\n",
    "out_df = pd.DataFrame(rows).sort_values(\"reels_index\").reset_index(drop=True)\n",
    "\n",
    "# 5) CSV 저장 (A: reels_index, B: temperature)\n",
    "out_df.to_csv(OUTPUT_CSV, index=False)\n",
    "\n",
    "# 6) 확인용 출력\n",
    "print(\"저장 완료 →\", OUTPUT_CSV)\n",
    "print(out_df.head(10).to_string(index=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
