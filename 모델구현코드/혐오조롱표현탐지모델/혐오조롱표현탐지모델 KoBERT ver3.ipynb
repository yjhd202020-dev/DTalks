{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_JwTKyXzbHqx"
      },
      "outputs": [],
      "source": [
        "# ==== 전맥락 + 화자태깅 학습 스크립트 ====\n",
        "import os, json, random, numpy as np, torch, re, glob\n",
        "from typing import List\n",
        "import pandas as pd\n",
        "from datasets import Dataset as HFDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoModelForSequenceClassification,\n",
        "    TrainingArguments, Trainer, DataCollatorWithPadding, EarlyStoppingCallback\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (1) 혹시 모를 잔여 마운트 해제\n",
        "!fusermount -u /content/drive 2>/dev/null || true\n",
        "!umount /content/drive 2>/dev/null || true\n",
        "\n",
        "# (2) 로컬에 남아있는 가짜 /content/drive 폴더/파일 제거 후 재생성\n",
        "!rm -rf /content/drive\n",
        "import os\n",
        "os.makedirs(\"/content/drive\", exist_ok=True)\n",
        "\n",
        "# (3) 강제 재마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# (4) 확인\n",
        "import os\n",
        "print(\"is mount?\", os.path.ismount(\"/content/drive\"))\n",
        "!ls -la /content/drive | head -n 20\n",
        "!ls -la /content/drive/MyDrive | head -n 20"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "7Wu9zkHnCJH1",
        "outputId": "c861b5e5-e48e-4f9c-bcba-e7f3c555d4c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3886233731.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# (3) 강제 재마운트\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# (4) 확인\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m     case = d.expect([\n\u001b[0m\u001b[1;32m    258\u001b[0m         \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pexpect/spawnbase.py\u001b[0m in \u001b[0;36mexpect\u001b[0;34m(self, pattern, timeout, searchwindowsize, async_, **kw)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0mcompiled_pattern_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_pattern_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m         return self.expect_list(compiled_pattern_list,\n\u001b[0m\u001b[1;32m    355\u001b[0m                 timeout, searchwindowsize, async_)\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pexpect/spawnbase.py\u001b[0m in \u001b[0;36mexpect_list\u001b[0;34m(self, pattern_list, timeout, searchwindowsize, async_, **kw)\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mexpect_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpect_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m     def expect_exact(self, pattern_list, timeout=-1, searchwindowsize=-1,\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pexpect/expect.py\u001b[0m in \u001b[0;36mexpect_loop\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0mincoming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspawn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_nonblocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelayafterread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelayafterread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m                 \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mincoming\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0;31m# Keep reading until exception or return.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5D1YCGWzbdgg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36128867-bdc9-4f1f-eba2-6f0255a7302a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "# -------------------- 0) 공통 설정 --------------------\n",
        "os.environ[\"HF_ALLOW_CODE_EXECUTION\"] = \"1\"\n",
        "os.environ[\"TRANSFORMERS_ALLOW_CODE_EXECUTION\"] = \"1\"\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
        "set_seed(42)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# *** 필요한 경로만 바꿔 ***\n",
        "DATA_PATH = \"/content/drive/MyDrive/metrics/혐오조롱표현탐지용데이터 15400개.jsonl\"\n",
        "BASE_DIR  = \"/content/drive/MyDrive/model_backup/results_ctx_tgt_best\"\n",
        "os.makedirs(BASE_DIR, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"after mount -> drive exists?\", os.path.isdir(\"/content/drive\"))\n",
        "print(\"MyDrive exists?\", os.path.isdir(\"/content/drive/MyDrive\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdDk465jBVyW",
        "outputId": "f920343c-f113-48c9-a75d-46f5dc96cf44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "after mount -> drive exists? True\n",
            "MyDrive exists? True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w0fCctBObuwl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "54f4b86c33c146b590d48f744380fd38",
            "2b80679333904c1bab76a887670f3a66",
            "62d0cedffb9249959d687722fbe36e2e",
            "34331cf819cf4b22b2d1e9128c3c242d",
            "0c1475964af7446bb6a650835c2bbdbc",
            "cc5d3d9f9cc7432c95ac05e074ee16f3",
            "602b2cdb98b145918d0d722eaa17fbbd",
            "75d1e590973441adacf9bc84fa58be3c",
            "c5eee03a97f142dfb2bcb3f0e787261b",
            "6487bbc36cc645ae9098d0aa08417ddb",
            "6e48cdb79fc84ba4b5f3832984e5b2dc",
            "d40721889e114704a18b6426e32b7cb7",
            "2bf9869ce0d24452a1b842ff260cdb6c",
            "f5bcd33f9db94e51b8a9992fdefb417b",
            "3490b9f7ed4045b795071cc8e35e2726",
            "7b131aa2fff247ac932e27a56ba80186",
            "d2270909444b466d8dc5e2b81f07c7c3",
            "6fe469c793a843999e7fc11bbc340a69",
            "4226f0c9d4334a83befa090204f42284",
            "eef3dca547884d3cafb060b90ecac7e0",
            "e6d8b8606749403da65e930c02f78eb9",
            "a6da62a68e7c4131abc290f7c3a199a6"
          ]
        },
        "outputId": "d99a1e72-f135-4d17-c6d2-ea12615a43e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 데이터 로드: 15211 rows\n",
            "  dialogue_id                                               text  label\n",
            "0         001  [CTX]\\nA: 부랴부랴 왔는데 아무도 안왔네. 시간개념들이 없네\\nB: 맞아. ...      1\n",
            "1         002  [CTX]\\nA: 인방 보는 남자는 거르는게 맞다\\nB: 특히 벗방보는 애들은 진짜...      0\n",
            "라벨 분포:\n",
            " label\n",
            "0    7957\n",
            "1    7254\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ KoBERT 로드\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/12168 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "54f4b86c33c146b590d48f744380fd38"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3043 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d40721889e114704a18b6426e32b7cb7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2237333616.py:217: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  hpo_trainer = Trainer(\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ KoBERT 로드\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-14 02:09:57,283] A new study created in memory with name: no-name-4a4843db-b59e-43fc-9793-a0b56283c9a0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔎 HPO 시작 (Optuna)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ KoBERT 로드\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2283' max='2283' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2283/2283 03:53, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Roc Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.059000</td>\n",
              "      <td>0.062201</td>\n",
              "      <td>0.957279</td>\n",
              "      <td>0.974838</td>\n",
              "      <td>0.934528</td>\n",
              "      <td>0.954258</td>\n",
              "      <td>0.993421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.035700</td>\n",
              "      <td>0.090378</td>\n",
              "      <td>0.950707</td>\n",
              "      <td>0.977256</td>\n",
              "      <td>0.917988</td>\n",
              "      <td>0.946695</td>\n",
              "      <td>0.993421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.017200</td>\n",
              "      <td>0.080740</td>\n",
              "      <td>0.958265</td>\n",
              "      <td>0.976259</td>\n",
              "      <td>0.935217</td>\n",
              "      <td>0.955297</td>\n",
              "      <td>0.994876</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-14 02:13:53,410] Trial 0 finished with value: 0.9552974304822246 and parameters: {'learning_rate': 1.319378718706203e-05, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 32, 'gradient_accumulation_steps': 2, 'weight_decay': 0.10962598352031049, 'warmup_ratio': 0.051246968699662845, 'lr_scheduler_type': 'linear', 'max_grad_norm': 0.7325620670571218, 'num_train_epochs': 3}. Best is trial 0 with value: 0.9552974304822246.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ KoBERT 로드\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3044' max='3044' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3044/3044 05:17, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Roc Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.076200</td>\n",
              "      <td>0.169657</td>\n",
              "      <td>0.882682</td>\n",
              "      <td>0.984071</td>\n",
              "      <td>0.766368</td>\n",
              "      <td>0.861682</td>\n",
              "      <td>0.990776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.039600</td>\n",
              "      <td>0.049267</td>\n",
              "      <td>0.970424</td>\n",
              "      <td>0.959487</td>\n",
              "      <td>0.979325</td>\n",
              "      <td>0.969304</td>\n",
              "      <td>0.994577</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.015900</td>\n",
              "      <td>0.047734</td>\n",
              "      <td>0.976011</td>\n",
              "      <td>0.967436</td>\n",
              "      <td>0.982771</td>\n",
              "      <td>0.975043</td>\n",
              "      <td>0.995235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.001100</td>\n",
              "      <td>0.068654</td>\n",
              "      <td>0.969767</td>\n",
              "      <td>0.972203</td>\n",
              "      <td>0.964163</td>\n",
              "      <td>0.968166</td>\n",
              "      <td>0.994750</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-14 02:19:13,904] Trial 1 finished with value: 0.9681660899653979 and parameters: {'learning_rate': 3.133444371761284e-05, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 16, 'gradient_accumulation_steps': 2, 'weight_decay': 0.01385857556212863, 'warmup_ratio': 0.23621876893445004, 'lr_scheduler_type': 'linear', 'max_grad_norm': 0.9305827512379382, 'num_train_epochs': 4}. Best is trial 1 with value: 0.9681660899653979.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ KoBERT 로드\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='384' max='384' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [384/384 02:40, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Roc Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.225500</td>\n",
              "      <td>0.082072</td>\n",
              "      <td>0.932632</td>\n",
              "      <td>0.978495</td>\n",
              "      <td>0.878015</td>\n",
              "      <td>0.925536</td>\n",
              "      <td>0.989614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.046100</td>\n",
              "      <td>0.042972</td>\n",
              "      <td>0.964837</td>\n",
              "      <td>0.969274</td>\n",
              "      <td>0.956582</td>\n",
              "      <td>0.962886</td>\n",
              "      <td>0.992924</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.028600</td>\n",
              "      <td>0.044302</td>\n",
              "      <td>0.961880</td>\n",
              "      <td>0.968421</td>\n",
              "      <td>0.951068</td>\n",
              "      <td>0.959666</td>\n",
              "      <td>0.993670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.018300</td>\n",
              "      <td>0.043638</td>\n",
              "      <td>0.965823</td>\n",
              "      <td>0.969993</td>\n",
              "      <td>0.957960</td>\n",
              "      <td>0.963939</td>\n",
              "      <td>0.993783</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-14 02:21:56,978] Trial 2 finished with value: 0.9639389736477115 and parameters: {'learning_rate': 1.5936149491629827e-05, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 32, 'gradient_accumulation_steps': 8, 'weight_decay': 0.0898588124052949, 'warmup_ratio': 0.13607602412400654, 'lr_scheduler_type': 'cosine', 'max_grad_norm': 0.9901711153532169, 'num_train_epochs': 4}. Best is trial 1 with value: 0.9681660899653979.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ KoBERT 로드\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='480' max='480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [480/480 03:19, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Roc Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.223800</td>\n",
              "      <td>0.050645</td>\n",
              "      <td>0.953664</td>\n",
              "      <td>0.945578</td>\n",
              "      <td>0.957960</td>\n",
              "      <td>0.951729</td>\n",
              "      <td>0.987713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.048700</td>\n",
              "      <td>0.048145</td>\n",
              "      <td>0.958265</td>\n",
              "      <td>0.974212</td>\n",
              "      <td>0.937285</td>\n",
              "      <td>0.955392</td>\n",
              "      <td>0.994282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.024500</td>\n",
              "      <td>0.043409</td>\n",
              "      <td>0.967138</td>\n",
              "      <td>0.972048</td>\n",
              "      <td>0.958649</td>\n",
              "      <td>0.965302</td>\n",
              "      <td>0.994534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.014200</td>\n",
              "      <td>0.076807</td>\n",
              "      <td>0.955636</td>\n",
              "      <td>0.972023</td>\n",
              "      <td>0.933839</td>\n",
              "      <td>0.952548</td>\n",
              "      <td>0.993833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.009200</td>\n",
              "      <td>0.068021</td>\n",
              "      <td>0.962537</td>\n",
              "      <td>0.970443</td>\n",
              "      <td>0.950379</td>\n",
              "      <td>0.960306</td>\n",
              "      <td>0.993401</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-14 02:25:19,535] Trial 3 finished with value: 0.9603064066852368 and parameters: {'learning_rate': 3.041536388981852e-05, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 32, 'gradient_accumulation_steps': 8, 'weight_decay': 0.08105201872285554, 'warmup_ratio': 0.1961631681881435, 'lr_scheduler_type': 'constant_with_warmup', 'max_grad_norm': 0.8076288957403834, 'num_train_epochs': 5}. Best is trial 1 with value: 0.9681660899653979.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ KoBERT 로드\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1524' max='1524' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1524/1524 05:04, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Roc Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.056600</td>\n",
              "      <td>0.069334</td>\n",
              "      <td>0.940519</td>\n",
              "      <td>0.974589</td>\n",
              "      <td>0.898691</td>\n",
              "      <td>0.935102</td>\n",
              "      <td>0.991848</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.042700</td>\n",
              "      <td>0.038383</td>\n",
              "      <td>0.970753</td>\n",
              "      <td>0.958895</td>\n",
              "      <td>0.980703</td>\n",
              "      <td>0.969676</td>\n",
              "      <td>0.994255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.015100</td>\n",
              "      <td>0.043761</td>\n",
              "      <td>0.970753</td>\n",
              "      <td>0.971607</td>\n",
              "      <td>0.966919</td>\n",
              "      <td>0.969257</td>\n",
              "      <td>0.995333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.003400</td>\n",
              "      <td>0.059680</td>\n",
              "      <td>0.965823</td>\n",
              "      <td>0.972632</td>\n",
              "      <td>0.955203</td>\n",
              "      <td>0.963839</td>\n",
              "      <td>0.995091</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-14 02:30:27,071] Trial 4 finished with value: 0.9638386648122392 and parameters: {'learning_rate': 2.6424958947429168e-05, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 16, 'gradient_accumulation_steps': 4, 'weight_decay': 0.09195722341351406, 'warmup_ratio': 0.28969701629752054, 'lr_scheduler_type': 'cosine', 'max_grad_norm': 0.8963893519373398, 'num_train_epochs': 4}. Best is trial 1 with value: 0.9681660899653979.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ KoBERT 로드\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='381' max='1905' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 381/1905 00:44 < 02:59, 8.49 it/s, Epoch 1/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Roc Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.055700</td>\n",
              "      <td>0.076038</td>\n",
              "      <td>0.940519</td>\n",
              "      <td>0.981061</td>\n",
              "      <td>0.892488</td>\n",
              "      <td>0.934681</td>\n",
              "      <td>0.993075</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-14 02:31:13,979] Trial 5 pruned. \n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ KoBERT 로드\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3044' max='3805' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3044/3805 03:11 < 00:47, 15.88 it/s, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Roc Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.061600</td>\n",
              "      <td>0.072019</td>\n",
              "      <td>0.945777</td>\n",
              "      <td>0.979851</td>\n",
              "      <td>0.904893</td>\n",
              "      <td>0.940881</td>\n",
              "      <td>0.993171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.048000</td>\n",
              "      <td>0.049477</td>\n",
              "      <td>0.967466</td>\n",
              "      <td>0.961119</td>\n",
              "      <td>0.971054</td>\n",
              "      <td>0.966061</td>\n",
              "      <td>0.993488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.024000</td>\n",
              "      <td>0.063235</td>\n",
              "      <td>0.967795</td>\n",
              "      <td>0.950700</td>\n",
              "      <td>0.983460</td>\n",
              "      <td>0.966802</td>\n",
              "      <td>0.993792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.011500</td>\n",
              "      <td>0.073877</td>\n",
              "      <td>0.966809</td>\n",
              "      <td>0.976023</td>\n",
              "      <td>0.953825</td>\n",
              "      <td>0.964796</td>\n",
              "      <td>0.993867</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-14 02:34:27,797] Trial 6 pruned. \n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ KoBERT 로드\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1522' max='2283' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1522/2283 02:40 < 01:20, 9.48 it/s, Epoch 2/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Roc Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.053400</td>\n",
              "      <td>0.070717</td>\n",
              "      <td>0.952350</td>\n",
              "      <td>0.973875</td>\n",
              "      <td>0.924879</td>\n",
              "      <td>0.948745</td>\n",
              "      <td>0.993113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.031600</td>\n",
              "      <td>0.080762</td>\n",
              "      <td>0.955307</td>\n",
              "      <td>0.976795</td>\n",
              "      <td>0.928325</td>\n",
              "      <td>0.951943</td>\n",
              "      <td>0.993976</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-14 02:37:09,900] Trial 7 pruned. \n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ KoBERT 로드\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='96' max='384' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 96/384 00:41 < 02:06, 2.27 it/s, Epoch 1/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Roc Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.246100</td>\n",
              "      <td>0.092493</td>\n",
              "      <td>0.912258</td>\n",
              "      <td>0.975884</td>\n",
              "      <td>0.836664</td>\n",
              "      <td>0.900928</td>\n",
              "      <td>0.984896</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-14 02:37:53,380] Trial 8 pruned. \n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ KoBERT 로드\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='762' max='1524' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 762/1524 01:26 < 01:26, 8.82 it/s, Epoch 2/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Roc Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.056600</td>\n",
              "      <td>0.050452</td>\n",
              "      <td>0.957936</td>\n",
              "      <td>0.969482</td>\n",
              "      <td>0.941420</td>\n",
              "      <td>0.955245</td>\n",
              "      <td>0.991921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.039300</td>\n",
              "      <td>0.037767</td>\n",
              "      <td>0.967795</td>\n",
              "      <td>0.970118</td>\n",
              "      <td>0.962095</td>\n",
              "      <td>0.966090</td>\n",
              "      <td>0.994177</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-14 02:39:21,370] Trial 9 pruned. \n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ KoBERT 로드\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4563' max='4563' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4563/4563 04:21, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Roc Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.044400</td>\n",
              "      <td>0.148934</td>\n",
              "      <td>0.922445</td>\n",
              "      <td>0.984064</td>\n",
              "      <td>0.851137</td>\n",
              "      <td>0.912786</td>\n",
              "      <td>0.992133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.052100</td>\n",
              "      <td>0.045795</td>\n",
              "      <td>0.974039</td>\n",
              "      <td>0.964141</td>\n",
              "      <td>0.982081</td>\n",
              "      <td>0.973028</td>\n",
              "      <td>0.994966</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.008400</td>\n",
              "      <td>0.062017</td>\n",
              "      <td>0.970095</td>\n",
              "      <td>0.974198</td>\n",
              "      <td>0.962784</td>\n",
              "      <td>0.968458</td>\n",
              "      <td>0.995374</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-14 02:43:45,188] Trial 10 finished with value: 0.9684575389948007 and parameters: {'learning_rate': 3.3488606479071704e-05, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 16, 'gradient_accumulation_steps': 1, 'weight_decay': 0.04475501618361846, 'warmup_ratio': 0.16345827033905022, 'lr_scheduler_type': 'linear', 'max_grad_norm': 0.9850833568331282, 'num_train_epochs': 3}. Best is trial 10 with value: 0.9684575389948007.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ KoBERT 로드\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3042' max='4563' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3042/4563 02:53 < 01:26, 17.55 it/s, Epoch 2/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Roc Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.045200</td>\n",
              "      <td>0.068181</td>\n",
              "      <td>0.968781</td>\n",
              "      <td>0.964384</td>\n",
              "      <td>0.970365</td>\n",
              "      <td>0.967365</td>\n",
              "      <td>0.992873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.063500</td>\n",
              "      <td>0.064027</td>\n",
              "      <td>0.964837</td>\n",
              "      <td>0.971910</td>\n",
              "      <td>0.953825</td>\n",
              "      <td>0.962783</td>\n",
              "      <td>0.994848</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-14 02:46:40,221] Trial 11 pruned. \n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ KoBERT 로드\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3042' max='4563' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3042/4563 02:54 < 01:27, 17.43 it/s, Epoch 2/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Roc Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.063400</td>\n",
              "      <td>0.124083</td>\n",
              "      <td>0.930003</td>\n",
              "      <td>0.979845</td>\n",
              "      <td>0.871123</td>\n",
              "      <td>0.922291</td>\n",
              "      <td>0.992113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.048700</td>\n",
              "      <td>0.063653</td>\n",
              "      <td>0.967466</td>\n",
              "      <td>0.975387</td>\n",
              "      <td>0.955892</td>\n",
              "      <td>0.965541</td>\n",
              "      <td>0.995292</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-14 02:49:36,435] Trial 12 pruned. \n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ KoBERT 로드\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='762' max='1143' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 762/1143 02:31 < 01:15, 5.02 it/s, Epoch 2/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Roc Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.051700</td>\n",
              "      <td>0.054780</td>\n",
              "      <td>0.957608</td>\n",
              "      <td>0.971469</td>\n",
              "      <td>0.938663</td>\n",
              "      <td>0.954784</td>\n",
              "      <td>0.992753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.032500</td>\n",
              "      <td>0.064933</td>\n",
              "      <td>0.945120</td>\n",
              "      <td>0.980539</td>\n",
              "      <td>0.902826</td>\n",
              "      <td>0.940079</td>\n",
              "      <td>0.994898</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-14 02:52:09,890] Trial 13 pruned. \n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ KoBERT 로드\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3042' max='6084' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3042/6084 02:53 < 02:53, 17.50 it/s, Epoch 2/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Roc Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.063300</td>\n",
              "      <td>0.063657</td>\n",
              "      <td>0.958593</td>\n",
              "      <td>0.975592</td>\n",
              "      <td>0.936595</td>\n",
              "      <td>0.955696</td>\n",
              "      <td>0.993908</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>0.069895</td>\n",
              "      <td>0.960237</td>\n",
              "      <td>0.927378</td>\n",
              "      <td>0.994487</td>\n",
              "      <td>0.959761</td>\n",
              "      <td>0.992914</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-14 02:55:05,570] Trial 14 pruned. \n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ KoBERT 로드\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='761' max='3044' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 761/3044 01:20 < 04:01, 9.45 it/s, Epoch 1/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Roc Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.066100</td>\n",
              "      <td>0.161998</td>\n",
              "      <td>0.915215</td>\n",
              "      <td>0.982215</td>\n",
              "      <td>0.837354</td>\n",
              "      <td>0.904018</td>\n",
              "      <td>0.989351</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-14 02:56:27,716] Trial 15 pruned. \n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ KoBERT 로드\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3042' max='4563' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3042/4563 02:53 < 01:26, 17.51 it/s, Epoch 2/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Roc Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.061800</td>\n",
              "      <td>0.092014</td>\n",
              "      <td>0.955307</td>\n",
              "      <td>0.977487</td>\n",
              "      <td>0.927636</td>\n",
              "      <td>0.951909</td>\n",
              "      <td>0.993038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.065100</td>\n",
              "      <td>0.052252</td>\n",
              "      <td>0.967138</td>\n",
              "      <td>0.960464</td>\n",
              "      <td>0.971054</td>\n",
              "      <td>0.965730</td>\n",
              "      <td>0.993924</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-14 02:59:23,161] Trial 16 pruned. \n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ KoBERT 로드\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='762' max='1905' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 762/1905 02:33 < 03:50, 4.96 it/s, Epoch 2/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Roc Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.046100</td>\n",
              "      <td>0.068818</td>\n",
              "      <td>0.950049</td>\n",
              "      <td>0.972364</td>\n",
              "      <td>0.921433</td>\n",
              "      <td>0.946214</td>\n",
              "      <td>0.991679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.035400</td>\n",
              "      <td>0.045026</td>\n",
              "      <td>0.965495</td>\n",
              "      <td>0.958447</td>\n",
              "      <td>0.969676</td>\n",
              "      <td>0.964029</td>\n",
              "      <td>0.993656</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-14 03:01:58,268] Trial 17 pruned. \n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ KoBERT 로드\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3042' max='4563' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3042/4563 02:50 < 01:25, 17.85 it/s, Epoch 2/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Roc Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.055500</td>\n",
              "      <td>0.079485</td>\n",
              "      <td>0.950707</td>\n",
              "      <td>0.977256</td>\n",
              "      <td>0.917988</td>\n",
              "      <td>0.946695</td>\n",
              "      <td>0.992719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.059400</td>\n",
              "      <td>0.051295</td>\n",
              "      <td>0.962208</td>\n",
              "      <td>0.936601</td>\n",
              "      <td>0.987595</td>\n",
              "      <td>0.961422</td>\n",
              "      <td>0.992585</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-14 03:04:50,338] Trial 18 pruned. \n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ KoBERT 로드\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1522' max='3044' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1522/3044 02:41 < 02:41, 9.42 it/s, Epoch 2/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Roc Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.052100</td>\n",
              "      <td>0.098292</td>\n",
              "      <td>0.940519</td>\n",
              "      <td>0.974589</td>\n",
              "      <td>0.898691</td>\n",
              "      <td>0.935102</td>\n",
              "      <td>0.991830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.035800</td>\n",
              "      <td>0.077037</td>\n",
              "      <td>0.948735</td>\n",
              "      <td>0.974359</td>\n",
              "      <td>0.916609</td>\n",
              "      <td>0.944602</td>\n",
              "      <td>0.992981</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-14 03:07:33,561] Trial 19 pruned. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🏁 HPO 완료: BestRun(run_id='10', objective=0.9684575389948007, hyperparameters={'learning_rate': 3.3488606479071704e-05, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 16, 'gradient_accumulation_steps': 1, 'weight_decay': 0.04475501618361846, 'warmup_ratio': 0.16345827033905022, 'lr_scheduler_type': 'linear', 'max_grad_norm': 0.9850833568331282, 'num_train_epochs': 3}, run_summary=None)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/model_backup/results_ctx_tgt_best/best_params.json'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2237333616.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;31m# 결과 저장\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBASE_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"best_params.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_ascii\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/model_backup/results_ctx_tgt_best/best_params.json'"
          ]
        }
      ],
      "source": [
        "def load_jsonl(path: str):\n",
        "    rows = []\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for lineno, line in enumerate(f, start=1):\n",
        "            s = line.strip()\n",
        "            if not s: continue\n",
        "            try:\n",
        "                rows.append(json.loads(s))\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"[WARN] JSON decode error at line {lineno}: {e}\")\n",
        "    return rows\n",
        "\n",
        "def map_label(lbl: str) -> int:\n",
        "    if not lbl: return 0\n",
        "    return 1 if str(lbl).strip().lower() == \"toxic\" else 0\n",
        "\n",
        "def ensure_speaker_prefixes(utts: List[str]) -> List[str]:\n",
        "    out = []\n",
        "    for i, u in enumerate(utts):\n",
        "        s = u.strip()\n",
        "        if s.startswith(\"A:\") or s.startswith(\"B:\"):\n",
        "            out.append(s)\n",
        "        else:\n",
        "            # 규칙이 없다면 A/B 번갈아 태깅 (데이터 포맷에 맞게 수정 가능)\n",
        "            out.append((\"A: \" if i % 2 == 0 else \"B: \") + s)\n",
        "    return out\n",
        "\n",
        "def get_speaker(line: str) -> str:\n",
        "    line = line.strip()\n",
        "    if line.startswith(\"A:\"): return \"A\"\n",
        "    if line.startswith(\"B:\"): return \"B\"\n",
        "    return \"U\"\n",
        "\n",
        "def build_input(utterances: List[str], k: int) -> str:\n",
        "    \"\"\"\n",
        "    전맥락 [CTX] ... [/CTX] + 타깃 화자 [TGT_SPK=X] ... [/TGT]\n",
        "    \"\"\"\n",
        "    utts = ensure_speaker_prefixes(utterances)\n",
        "    ctx = utts[:k]\n",
        "    tgt = utts[k]\n",
        "    tgt_spk = get_speaker(tgt)\n",
        "    parts = []\n",
        "    if ctx:\n",
        "        parts.append(\"[CTX]\")\n",
        "        parts.extend(ctx)\n",
        "        parts.append(\"[/CTX]\")\n",
        "    parts.append(f\"[TGT_SPK={tgt_spk}] {tgt} [/TGT]\")\n",
        "    return \"\\n\".join(parts)\n",
        "\n",
        "raw = load_jsonl(DATA_PATH)\n",
        "print(f\"✅ 데이터 로드: {len(raw)} rows\")\n",
        "\n",
        "records = []\n",
        "bad = 0\n",
        "for r in raw:\n",
        "    utts = r.get(\"utterances\") or r.get(\"context\") or []\n",
        "    idx = r.get(\"target_index\", None)\n",
        "    lbl = r.get(\"label\", None)\n",
        "    if not isinstance(utts, list) or idx is None or idx < 0 or idx >= len(utts):\n",
        "        bad += 1\n",
        "        continue\n",
        "    records.append({\n",
        "        \"dialogue_id\": r.get(\"dialogue_id\", r.get(\"id\", \"\")),\n",
        "        \"text\": build_input(utts, idx),\n",
        "        \"label\": map_label(lbl)\n",
        "    })\n",
        "if bad:\n",
        "    print(f\"⚠️ 무시된 레코드: {bad}\")\n",
        "\n",
        "df = pd.DataFrame(records)\n",
        "print(df.head(2))\n",
        "print(\"라벨 분포:\\n\", df[\"label\"].value_counts())\n",
        "\n",
        "def load_tok_and_model():\n",
        "    try:\n",
        "        tok = AutoTokenizer.from_pretrained(\"monologg/kobert\", trust_remote_code=True)\n",
        "        mdl = AutoModelForSequenceClassification.from_pretrained(\n",
        "            \"monologg/kobert\", trust_remote_code=True, num_labels=2\n",
        "        )\n",
        "        print(\"✅ KoBERT 로드\")\n",
        "    except Exception as e:\n",
        "        print(\"❌ KoBERT 실패 → mBERT로 대체:\", e)\n",
        "        tok = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "        mdl = AutoModelForSequenceClassification.from_pretrained(\n",
        "            \"bert-base-multilingual-cased\", num_labels=2\n",
        "        )\n",
        "        print(\"✅ mBERT 로드\")\n",
        "    return tok, mdl\n",
        "\n",
        "tokenizer, _ = load_tok_and_model()\n",
        "orig_save_vocab = getattr(tokenizer, \"save_vocabulary\", None)\n",
        "if callable(orig_save_vocab):\n",
        "    def _patched_save_vocabulary(save_directory, *args, **kwargs):\n",
        "        if \"filename_prefix\" in kwargs: kwargs.pop(\"filename_prefix\")\n",
        "        return orig_save_vocab(save_directory, *args, **kwargs)\n",
        "    tokenizer.save_vocabulary = _patched_save_vocabulary\n",
        "# 스페셜 토큰 등록 (권장)\n",
        "SPECIAL_TOKENS = {\n",
        "    \"additional_special_tokens\": [\"[CTX]\", \"[/CTX]\", \"[TGT_SPK=A]\", \"[TGT_SPK=B]\", \"[TGT_SPK=U]\", \"[TGT]\", \"[/TGT]\"]\n",
        "}\n",
        "tokenizer.add_special_tokens(SPECIAL_TOKENS)\n",
        "\n",
        "def model_init():\n",
        "    # KoBERT 우선, 실패 시 mBERT 대체 (원래 함수 재사용)\n",
        "    _, mdl = load_tok_and_model()\n",
        "    # 스페셜 토큰 반영\n",
        "    mdl.resize_token_embeddings(len(tokenizer))\n",
        "    # 레이블 매핑 유지\n",
        "    mdl.config.label2id = {\"non_toxic\": 0, \"toxic\": 1}\n",
        "    mdl.config.id2label = {0: \"non_toxic\", 1: \"toxic\"}\n",
        "    return mdl\n",
        "\n",
        "\n",
        "# -------------------- 5) 메트릭/트레이너 --------------------\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "    out = {\n",
        "        \"accuracy\": accuracy_score(labels, preds),\n",
        "        \"precision\": precision_score(labels, preds, zero_division=0),\n",
        "        \"recall\": recall_score(labels, preds, zero_division=0),\n",
        "        \"f1\": f1_score(labels, preds, zero_division=0),\n",
        "    }\n",
        "    try:\n",
        "        prob_pos = (np.exp(logits) / np.exp(logits).sum(-1, keepdims=True))[:, 1]\n",
        "        out[\"roc_auc\"] = roc_auc_score(labels, prob_pos)\n",
        "    except Exception:\n",
        "        out[\"roc_auc\"] = float(\"nan\")\n",
        "    return out\n",
        "\n",
        "\n",
        "# -------------------- 4) 가중치 & Focal Loss --------------------\n",
        "pos = int((train_df[\"label\"] == 1).sum())\n",
        "neg = int((train_df[\"label\"] == 0).sum())\n",
        "ratio = neg / max(1, pos)\n",
        "w_pos = float(min(3.0, max(1.0, ratio)))  # 1~3로 clamp (과탐 방지)\n",
        "class_weights = torch.tensor([1.0, w_pos], dtype=torch.float32).to(device)\n",
        "\n",
        "import torch.nn.functional as F\n",
        "class FocalLoss(torch.nn.Module):\n",
        "    def __init__(self, alpha=None, gamma=1.5, reduction=\"mean\"):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha  # class_weights 텐서\n",
        "        self.gamma = gamma\n",
        "        self.reduction = reduction\n",
        "    def forward(self, logits, target):\n",
        "        ce = F.cross_entropy(logits, target, weight=self.alpha, reduction=\"none\")\n",
        "        pt = torch.softmax(logits, dim=-1).gather(1, target.view(-1,1)).squeeze(1).clamp_(1e-6, 1-1e-6)\n",
        "        loss = ((1-pt) ** self.gamma) * ce\n",
        "        return loss.mean() if self.reduction==\"mean\" else loss.sum()\n",
        "\n",
        "focal = FocalLoss(alpha=class_weights, gamma=1.5)\n",
        "\n",
        "def custom_compute_loss(model, inputs, return_outputs=False, **kwargs):\n",
        "    labels = inputs.get(\"labels\")\n",
        "    outputs = model(**{k: v for k, v in inputs.items() if k != \"labels\"})\n",
        "    logits = outputs.logits\n",
        "    loss = focal(logits.view(-1, 2), labels.view(-1))\n",
        "    return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "# -------------------- 3) Dataset/Tokenize --------------------\n",
        "def tokenize_fn(batch):\n",
        "    return tokenizer(batch[\"text\"], truncation=True, padding=False)\n",
        "\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df[\"label\"])\n",
        "train_ds = HFDataset.from_pandas(train_df.reset_index(drop=True))\n",
        "val_ds   = HFDataset.from_pandas(val_df.reset_index(drop=True))\n",
        "\n",
        "remove_cols = [c for c in [\"text\", \"dialogue_id\", \"__index_level_0__\"] if c in train_ds.column_names]\n",
        "train_ds = train_ds.map(tokenize_fn, batched=True, remove_columns=remove_cols)\n",
        "val_ds   = val_ds.map(tokenize_fn,   batched=True, remove_columns=remove_cols)\n",
        "train_ds = train_ds.rename_column(\"label\", \"labels\")\n",
        "val_ds   = val_ds.rename_column(\"label\", \"labels\")\n",
        "train_ds.set_format(type=\"torch\")\n",
        "val_ds.set_format(type=\"torch\")\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "def hp_space_optuna(trial):\n",
        "    return {\n",
        "        # loguniform: 1e-5 ~ 5e-5 범위에서 학습률 탐색\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 5e-5, log=True),\n",
        "        # 배치·가적은 데이터/메모리 균형용\n",
        "        \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [8, 16]),\n",
        "        \"per_device_eval_batch_size\": trial.suggest_categorical(\"per_device_eval_batch_size\", [16, 32]),\n",
        "        \"gradient_accumulation_steps\": trial.suggest_categorical(\"gradient_accumulation_steps\", [1, 2, 4, 8]),\n",
        "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 0.01, 0.12),\n",
        "        \"warmup_ratio\": trial.suggest_float(\"warmup_ratio\", 0.05, 0.30),\n",
        "        \"lr_scheduler_type\": trial.suggest_categorical(\"lr_scheduler_type\",\n",
        "                              [\"linear\", \"cosine\", \"constant_with_warmup\", \"polynomial\"]),\n",
        "        \"max_grad_norm\": trial.suggest_float(\"max_grad_norm\", 0.5, 1.0),\n",
        "        # 에폭도 가볍게 탐색 (과적합 방지 위해 3~5)\n",
        "        \"num_train_epochs\": trial.suggest_int(\"num_train_epochs\", 3, 5),\n",
        "    }\n",
        "\n",
        "def compute_objective(metrics):\n",
        "    # f1 기준 최대화\n",
        "    return metrics.get(\"eval_f1\", 0.0)\n",
        "\n",
        "# ==================== [HPO] Trainer (탐색용) ====================\n",
        "# 주의: HPO에서는 model 대신 model_init을 전달해야 함\n",
        "hpo_args = TrainingArguments(\n",
        "    output_dir=os.path.join(BASE_DIR, \"hpo\"),\n",
        "    logging_dir=os.path.join(BASE_DIR, \"hpo_logs\"),\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"no\",\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=50,\n",
        "    load_best_model_at_end=False,     # 탐색에서 best 로드는 비활성화\n",
        "    metric_for_best_model=\"f1\",\n",
        "    greater_is_better=True,\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    dataloader_pin_memory=False,\n",
        "    report_to=[]\n",
        ")\n",
        "\n",
        "hpo_trainer = Trainer(\n",
        "    model_init=model_init,\n",
        "    args=hpo_args,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=val_ds,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],\n",
        ")\n",
        "# focal loss 적용 (기존과 동일)\n",
        "hpo_trainer.compute_loss = custom_compute_loss\n",
        "\n",
        "print(\"🔎 HPO 시작 (Optuna)\")\n",
        "best_run = hpo_trainer.hyperparameter_search(\n",
        "    hp_space=hp_space_optuna,\n",
        "    direction=\"maximize\",\n",
        "    compute_objective=compute_objective,\n",
        "    n_trials=20,          # 필요에 따라 늘리기(시간↑)\n",
        "    backend=\"optuna\",     # 기본 optuna\n",
        ")\n",
        "print(\"🏁 HPO 완료:\", best_run)\n",
        "\n",
        "# 결과 저장\n",
        "with open(os.path.join(BASE_DIR, \"best_params.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(best_run.hyperparameters, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "BEST_PARAMS.update({\n",
        "    \"learning_rate\": best_run.hyperparameters[\"learning_rate\"],\n",
        "    \"per_device_train_batch_size\": best_run.hyperparameters[\"per_device_train_batch_size\"],\n",
        "    \"per_device_eval_batch_size\": best_run.hyperparameters[\"per_device_eval_batch_size\"],\n",
        "    \"gradient_accumulation_steps\": best_run.hyperparameters[\"gradient_accumulation_steps\"],\n",
        "    \"weight_decay\": best_run.hyperparameters[\"weight_decay\"],\n",
        "    \"warmup_ratio\": best_run.hyperparameters[\"warmup_ratio\"],\n",
        "    \"lr_scheduler_type\": best_run.hyperparameters[\"lr_scheduler_type\"],\n",
        "})\n",
        "NUM_TRAIN_EPOCHS = int(best_run.hyperparameters.get(\"num_train_epochs\", NUM_TRAIN_EPOCHS))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BEST_PARAMS = {\n",
        "    \"learning_rate\": 3.3488606479071704e-05,\n",
        "    \"per_device_train_batch_size\": 8,\n",
        "    \"per_device_eval_batch_size\": 16,\n",
        "    \"gradient_accumulation_steps\": 1,\n",
        "    \"weight_decay\": 0.04475501618361846,\n",
        "    \"warmup_ratio\": 0.16345827033905022,\n",
        "    \"lr_scheduler_type\": \"linear\",\n",
        "    \"max_grad_norm\": 0.9850833568331282\n",
        "}\n",
        "\n",
        "NUM_TRAIN_EPOCHS = 3  # HPO 결과 반영\n",
        "\n",
        "final_args = TrainingArguments(\n",
        "    output_dir=BASE_DIR,\n",
        "    logging_dir=os.path.join(BASE_DIR, \"logs\"),\n",
        "    eval_strategy=\"epoch\",  # eval_strategy → evaluation_strategy (정식 파라미터명)\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=2,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    greater_is_better=True,\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    dataloader_pin_memory=False,\n",
        "    num_train_epochs=NUM_TRAIN_EPOCHS,\n",
        "    **BEST_PARAMS,\n",
        "    report_to=[]\n",
        ")\n",
        "\n",
        "final_trainer = Trainer(\n",
        "    model_init=model_init,  # 최종 학습도 동일 초기화 경로 사용\n",
        "    args=final_args,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=val_ds,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],\n",
        ")\n",
        "final_trainer.compute_loss = custom_compute_loss\n",
        "\n",
        "print(\"🚀 최종 학습 시작 (HPO 최적 파라미터 적용)\")\n",
        "final_trainer.train()\n",
        "print(\"✅ 최종 학습 종료\")\n",
        "\n",
        "import numpy as np\n",
        "def find_best_threshold(trainer, val_ds, target_metric=\"f1\"):\n",
        "    preds = trainer.predict(val_ds)\n",
        "    logits = preds.predictions\n",
        "    labels = preds.label_ids\n",
        "    prob_toxic = (np.exp(logits) / np.exp(logits).sum(-1, keepdims=True))[:, 1]\n",
        "    best_t, best = 0.5, -1\n",
        "    for t in np.linspace(0.05, 0.95, 19):\n",
        "        yhat = (prob_toxic >= t).astype(int)\n",
        "        m = {\n",
        "            \"accuracy\": accuracy_score(labels, yhat),\n",
        "            \"precision\": precision_score(labels, yhat, zero_division=0),\n",
        "            \"recall\": recall_score(labels, yhat, zero_division=0),\n",
        "            \"f1\": f1_score(labels, yhat, zero_division=0),\n",
        "        }[target_metric]\n",
        "        if m > best:\n",
        "            best, best_t = m, t\n",
        "    return float(best_t)\n",
        "\n",
        "best_t = find_best_threshold(final_trainer, val_ds, target_metric=\"f1\")\n",
        "os.makedirs(BASE_DIR, exist_ok=True)\n",
        "with open(os.path.join(BASE_DIR, \"threshold.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump({\"threshold\": best_t}, f, ensure_ascii=False, indent=2)\n",
        "print(\"✅ 최적 threshold 저장:\", best_t)\n",
        "\n",
        "\n",
        "final_trainer.save_model(BASE_DIR)           # 모델 저장\n",
        "tokenizer.save_pretrained(BASE_DIR)          # 토크나이저 저장\n",
        "print(\"✅ 모델과 토크나이저 저장 완료:\", BASE_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "c2oqZlNmjV-p",
        "outputId": "12320af5-4bed-45ad-e085-3166f5fe10a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2513236155.py:30: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  final_trainer = Trainer(\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ KoBERT 로드\n",
            "🚀 최종 학습 시작 (HPO 최적 파라미터 적용)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ KoBERT 로드\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4563' max='4563' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4563/4563 04:41, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Roc Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.068500</td>\n",
              "      <td>0.148934</td>\n",
              "      <td>0.922445</td>\n",
              "      <td>0.984064</td>\n",
              "      <td>0.851137</td>\n",
              "      <td>0.912786</td>\n",
              "      <td>0.992133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.041900</td>\n",
              "      <td>0.045795</td>\n",
              "      <td>0.974039</td>\n",
              "      <td>0.964141</td>\n",
              "      <td>0.982081</td>\n",
              "      <td>0.973028</td>\n",
              "      <td>0.994966</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.014100</td>\n",
              "      <td>0.062914</td>\n",
              "      <td>0.969767</td>\n",
              "      <td>0.974843</td>\n",
              "      <td>0.961406</td>\n",
              "      <td>0.968078</td>\n",
              "      <td>0.995384</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 최종 학습 종료\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 최적 threshold 저장: 0.44999999999999996\n",
            "✅ 모델과 토크나이저 저장 완료: /content/drive/MyDrive/model_backup/results_ctx_tgt_best\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6iOiTfpNJG1",
        "outputId": "75737e2c-345f-4493-d6c5-3fd7bce4e5b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== 전맥락 + 화자태깅 추론 스크립트 ====\n",
        "import os, json, torch, re\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# (학습과 동일 경로)\n",
        "BASE_DIR = \"/content/drive/MyDrive/model_backup/results_ctx_tgt_best\"\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "def load_threshold(model_dir, default=0.1):\n",
        "    p = os.path.join(model_dir, \"threshold.json\")\n",
        "    if os.path.exists(p):\n",
        "        try:\n",
        "            return float(json.load(open(p, \"r\", encoding=\"utf-8\"))[\"threshold\"])\n",
        "        except Exception:\n",
        "            pass\n",
        "    return default\n",
        "\n",
        "def ensure_speaker_prefixes(utts):\n",
        "    out = []\n",
        "    for i, u in enumerate(utts):\n",
        "        s = u.strip()\n",
        "        if s.startswith(\"A:\") or s.startswith(\"B:\"):\n",
        "            out.append(s)\n",
        "        else:\n",
        "            out.append((\"A: \" if i % 2 == 0 else \"B: \") + s)\n",
        "    return out\n",
        "\n",
        "def get_speaker(line: str) -> str:\n",
        "    line = line.strip()\n",
        "    if line.startswith(\"A:\"): return \"A\"\n",
        "    if line.startswith(\"B:\"): return \"B\"\n",
        "    return \"U\"\n",
        "\n",
        "def build_input_for_infer(utterances):\n",
        "    assert len(utterances) >= 2, \"최소 2줄 이상 필요\"\n",
        "    utts = ensure_speaker_prefixes(utterances)\n",
        "    k = len(utts) - 1\n",
        "    ctx_lines = utts[:k]\n",
        "    tgt_line  = utts[k]\n",
        "    tgt_spk   = get_speaker(tgt_line)\n",
        "    parts = []\n",
        "    if ctx_lines:\n",
        "        parts.append(\"[CTX]\")\n",
        "        parts.extend(ctx_lines)\n",
        "        parts.append(\"[/CTX]\")\n",
        "    parts.append(f\"[TGT_SPK={tgt_spk}] {tgt_line} [/TGT]\")\n",
        "    return \"\\n\".join(parts)\n",
        "\n",
        "# (선택) 응급 가드 – 고백/연애 맥락의 \"~줄래?\" 과탐 완화\n",
        "LOVE_SAFE = re.compile(\n",
        "    r\"(사랑|좋아|결혼|연애|고백|프로포즈).*(줄래|주겠니|줄\\s*수\\s*있어)\\??$\",\n",
        "    re.IGNORECASE\n",
        ")\n",
        "def apply_guards(formatted_text: str, pred_label: str, prob_toxic: float, threshold: float) -> str:\n",
        "    if pred_label == \"toxic\" and LOVE_SAFE.search(formatted_text.replace(\"\\n\", \" \")):\n",
        "        if prob_toxic < max(0.9, threshold + 0.3):\n",
        "            return \"non_toxic\"\n",
        "    return pred_label\n",
        "\n",
        "# 로드\n",
        "tokenizer = AutoTokenizer.from_pretrained(BASE_DIR, trust_remote_code=True)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(BASE_DIR, trust_remote_code=True).to(DEVICE).eval()\n",
        "TH = load_threshold(BASE_DIR, default=0.5)\n",
        "\n",
        "@torch.inference_mode()\n",
        "def predict_toxic_with_context(utterances, threshold=None, use_guard=True):\n",
        "    \"\"\"\n",
        "    utterances: [\"A: ...\", \"B: ...\", \"A: ...\", \"B: ...\"] (길이 2 이상 자유)\n",
        "    threshold: None이면 저장된 best threshold 사용\n",
        "    \"\"\"\n",
        "    if threshold is None:\n",
        "        threshold = TH\n",
        "\n",
        "    formatted = build_input_for_infer(utterances)\n",
        "    inputs = tokenizer(formatted, truncation=True, return_tensors=\"pt\")\n",
        "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "    logits = model(**inputs).logits\n",
        "    probs = torch.softmax(logits, dim=-1).squeeze(0).tolist()\n",
        "    prob_non_toxic, prob_toxic = float(probs[0]), float(probs[1])\n",
        "\n",
        "    pred_id = int(prob_toxic >= threshold)\n",
        "    pred_label = {0:\"non_toxic\", 1:\"toxic\"}[pred_id]\n",
        "\n",
        "    if use_guard:\n",
        "        pred_label = apply_guards(formatted, pred_label, prob_toxic, threshold)\n",
        "\n",
        "    return {\n",
        "        \"use_context\": \"ALL\",\n",
        "        \"text\": formatted,\n",
        "        \"prob_toxic\": prob_toxic,\n",
        "        \"threshold\": threshold,\n",
        "        \"pred_label\": pred_label\n",
        "    }\n",
        "\n",
        "# ---- 콘솔 입력 예시 ----\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"A→B→A→B 순서로 최대 4줄(혹은 그 이상) 입력하세요. (빈 줄로 종료)\")\n",
        "    lines = []\n",
        "    for i in range(8):  # 원하면 더 길게 입력\n",
        "        s = input(f\"{i+1}번째 줄: \").strip()\n",
        "        if not s: break\n",
        "        lines.append(s)\n",
        "\n",
        "    if len(lines) < 2:\n",
        "        raise ValueError(\"최소 2줄 이상 입력해야 합니다.\")\n",
        "\n",
        "    out = predict_toxic_with_context(lines)\n",
        "    print(\"\\n=== 결과 ===\")\n",
        "    print(\"입력(모델에 투입된 실제 문자열):\")\n",
        "    print(out[\"text\"])\n",
        "    print(\"\\n예측:\")\n",
        "    print({\"prob_toxic\": out[\"prob_toxic\"], \"threshold\": out[\"threshold\"], \"pred_label\": out[\"pred_label\"]})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HU8p5smX2nju",
        "outputId": "ea2234f5-6aa6-401f-8a1a-e356bb680d7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A→B→A→B 순서로 최대 4줄(혹은 그 이상) 입력하세요. (빈 줄로 종료)\n",
            "1번째 줄: A: 오늘 비 오니까 국물 있는거 먹자\n",
            "2번째 줄: B: 칼국수 어때?\n",
            "3번째 줄: A: 좋지!\n",
            "4번째 줄: B: 넌 면보다 질척거림 ㅋㅋ\n",
            "5번째 줄: \n",
            "\n",
            "=== 결과 ===\n",
            "입력(모델에 투입된 실제 문자열):\n",
            "[CTX]\n",
            "A: 오늘 비 오니까 국물 있는거 먹자\n",
            "B: 칼국수 어때?\n",
            "A: 좋지!\n",
            "[/CTX]\n",
            "[TGT_SPK=B] B: 넌 면보다 질척거림 ㅋㅋ [/TGT]\n",
            "\n",
            "예측:\n",
            "{'prob_toxic': 0.012123801745474339, 'threshold': 0.44999999999999996, 'pred_label': 'non_toxic'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "data_new = []\n",
        "with open(\"/content/drive/MyDrive/metrics/추가데이터 150개#1.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        line = line.strip()\n",
        "        if not line:  # 빈 줄 건너뛰기\n",
        "            continue\n",
        "        try:\n",
        "            data_new.append(json.loads(line))\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(\"❌ JSONDecodeError 발생 줄:\", line)\n",
        "            raise e\n",
        "\n",
        "print(len(data_new), \"개 로드 완료\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_W1GNYn-l0EP",
        "outputId": "511f73dd-343c-427b-fd6c-1a9062631c34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "150 개 로드 완료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NEW_DATA_PATH = \"/content/drive/MyDrive/metrics/추가데이터 150개#1.jsonl\"\n",
        "BASE_DIR = \"/content/drive/MyDrive/model_backup/results_ctx_tgt_best\"\n",
        "# ===== 2. JSONL 로드 =====\n",
        "data_new = load_jsonl(NEW_DATA_PATH)\n",
        "print(f\"📂 추가 데이터 로드: {len(data_new)} rows\")\n",
        "\n",
        "# ===== 3. 기존 전처리 재사용 =====\n",
        "records_new = []\n",
        "bad = 0\n",
        "for r in data_new:\n",
        "    utts = r.get(\"utterances\") or r.get(\"context\") or []\n",
        "    idx = r.get(\"target_index\", None)\n",
        "    lbl = r.get(\"label\", None)\n",
        "    if not isinstance(utts, list) or idx is None or idx < 0 or idx >= len(utts):\n",
        "        bad += 1\n",
        "        continue\n",
        "    records_new.append({\n",
        "        \"dialogue_id\": r.get(\"dialogue_id\", r.get(\"id\", \"\")),\n",
        "        \"text\": build_input(utts, idx),\n",
        "        \"label\": map_label(lbl)\n",
        "    })\n",
        "if bad:\n",
        "    print(f\"⚠️ 무시된 레코드: {bad}\")\n",
        "\n",
        "# ===== 4. Dataset 변환 =====\n",
        "df_new = pd.DataFrame(records_new)\n",
        "print(\"라벨 분포:\\n\", df_new[\"label\"].value_counts())\n",
        "\n",
        "new_ds = HFDataset.from_pandas(df_new.rename(columns={\"label\": \"labels\"}))\n",
        "\n",
        "def tokenize(batch):\n",
        "    return tokenizer(batch[\"text\"], truncation=True, padding=\"max_length\", max_length=256)\n",
        "\n",
        "new_ds = new_ds.map(tokenize, batched=True)\n",
        "keep_cols = [\"input_ids\", \"attention_mask\", \"labels\"]\n",
        "new_ds.set_format(type=\"torch\", columns=keep_cols)\n",
        "\n",
        "# ===== 5. 기존 모델 로드 =====\n",
        "model = AutoModelForSequenceClassification.from_pretrained(BASE_DIR, trust_remote_code=True)\n",
        "\n",
        "# ===== 5-1. KoBERT 토크나이저 저장 버그 패치 =====\n",
        "orig_save_vocab = getattr(tokenizer, \"save_vocabulary\", None)\n",
        "if callable(orig_save_vocab):\n",
        "    def _patched_save_vocabulary(save_directory, *args, **kwargs):\n",
        "        if \"filename_prefix\" in kwargs:\n",
        "            kwargs.pop(\"filename_prefix\")\n",
        "        return orig_save_vocab(save_directory, *args, **kwargs)\n",
        "    tokenizer.save_vocabulary = _patched_save_vocabulary\n",
        "\n",
        "# ===== 6. 이어서 학습 =====\n",
        "continue_args = TrainingArguments(\n",
        "    output_dir=BASE_DIR,\n",
        "    logging_dir=os.path.join(BASE_DIR, \"logs_continue\"),\n",
        "    eval_strategy=\"epoch\",     # eval_strategy → evaluation_strategy\n",
        "    logging_strategy=\"steps\",        # step 단위로 로그\n",
        "    logging_steps=10,                 # 10 step마다 로그 출력\n",
        "    disable_tqdm=False,               # tqdm 진행바 표시\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    greater_is_better=True,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=16,\n",
        "    learning_rate=3e-5,\n",
        "    num_train_epochs=2,\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    report_to=[]\n",
        ")\n",
        "\n",
        "continue_trainer = Trainer(\n",
        "    model=model,\n",
        "    args=continue_args,\n",
        "    train_dataset=new_ds,\n",
        "    eval_dataset=val_ds,  # 기존 검증 데이터\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "print(\"🚀 추가 데이터로 이어서 학습 시작\")\n",
        "continue_trainer.train()\n",
        "print(\"✅ 추가 학습 완료\")\n",
        "\n",
        "# ===== 7. 모델 저장 =====\n",
        "continue_trainer.save_model(BASE_DIR)\n",
        "tokenizer.save_pretrained(BASE_DIR)\n",
        "print(\"💾 모델과 토크나이저 저장 완료:\", BASE_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374,
          "referenced_widgets": [
            "54a1991337714e6d966a9b765b529c93",
            "5ad51f7de9e24179a8f49b26c840ef6b",
            "2fc52e61ffd94771a49062a3d4b7d5b7",
            "bdc72d88a3064cfab5bc235e05c47bb1",
            "f9ece16a3c884aa5b35e867cbc6789f3",
            "03a096c5b6b74990add0d92a218c59b2",
            "a97c899a52d947cf908acddec60532cf",
            "f3078ecd322a4dbead44a84360062fd3",
            "3cf6e71eee014f288590f47fa9d3defc",
            "e433dbb3de1b4120aeba9a2a1083bab0",
            "f3df7c035ce44bbb80b06edc28e0662f"
          ]
        },
        "id": "Co0qeD17nGh2",
        "outputId": "ead8238e-90d0-4c19-e776-4ad805ec4b1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📂 추가 데이터 로드: 150 rows\n",
            "라벨 분포:\n",
            " label\n",
            "0    150\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/150 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "54a1991337714e6d966a9b765b529c93"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2793238249.py:70: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  continue_trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 추가 데이터로 이어서 학습 시작\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [38/38 00:19, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Roc Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.273200</td>\n",
              "      <td>1.987557</td>\n",
              "      <td>0.524811</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.003446</td>\n",
              "      <td>0.006868</td>\n",
              "      <td>0.847923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.011300</td>\n",
              "      <td>2.213041</td>\n",
              "      <td>0.523168</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.895848</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 추가 학습 완료\n",
            "💾 모델과 토크나이저 저장 완료: /content/drive/MyDrive/model_backup/results_ctx_tgt_best\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "whFl4rVq2st-"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "54f4b86c33c146b590d48f744380fd38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2b80679333904c1bab76a887670f3a66",
              "IPY_MODEL_62d0cedffb9249959d687722fbe36e2e",
              "IPY_MODEL_34331cf819cf4b22b2d1e9128c3c242d"
            ],
            "layout": "IPY_MODEL_0c1475964af7446bb6a650835c2bbdbc"
          }
        },
        "2b80679333904c1bab76a887670f3a66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc5d3d9f9cc7432c95ac05e074ee16f3",
            "placeholder": "​",
            "style": "IPY_MODEL_602b2cdb98b145918d0d722eaa17fbbd",
            "value": "Map: 100%"
          }
        },
        "62d0cedffb9249959d687722fbe36e2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75d1e590973441adacf9bc84fa58be3c",
            "max": 12168,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c5eee03a97f142dfb2bcb3f0e787261b",
            "value": 12168
          }
        },
        "34331cf819cf4b22b2d1e9128c3c242d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6487bbc36cc645ae9098d0aa08417ddb",
            "placeholder": "​",
            "style": "IPY_MODEL_6e48cdb79fc84ba4b5f3832984e5b2dc",
            "value": " 12168/12168 [00:04&lt;00:00, 2598.16 examples/s]"
          }
        },
        "0c1475964af7446bb6a650835c2bbdbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc5d3d9f9cc7432c95ac05e074ee16f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "602b2cdb98b145918d0d722eaa17fbbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75d1e590973441adacf9bc84fa58be3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5eee03a97f142dfb2bcb3f0e787261b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6487bbc36cc645ae9098d0aa08417ddb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e48cdb79fc84ba4b5f3832984e5b2dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d40721889e114704a18b6426e32b7cb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2bf9869ce0d24452a1b842ff260cdb6c",
              "IPY_MODEL_f5bcd33f9db94e51b8a9992fdefb417b",
              "IPY_MODEL_3490b9f7ed4045b795071cc8e35e2726"
            ],
            "layout": "IPY_MODEL_7b131aa2fff247ac932e27a56ba80186"
          }
        },
        "2bf9869ce0d24452a1b842ff260cdb6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2270909444b466d8dc5e2b81f07c7c3",
            "placeholder": "​",
            "style": "IPY_MODEL_6fe469c793a843999e7fc11bbc340a69",
            "value": "Map: 100%"
          }
        },
        "f5bcd33f9db94e51b8a9992fdefb417b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4226f0c9d4334a83befa090204f42284",
            "max": 3043,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eef3dca547884d3cafb060b90ecac7e0",
            "value": 3043
          }
        },
        "3490b9f7ed4045b795071cc8e35e2726": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6d8b8606749403da65e930c02f78eb9",
            "placeholder": "​",
            "style": "IPY_MODEL_a6da62a68e7c4131abc290f7c3a199a6",
            "value": " 3043/3043 [00:01&lt;00:00, 2575.44 examples/s]"
          }
        },
        "7b131aa2fff247ac932e27a56ba80186": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2270909444b466d8dc5e2b81f07c7c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fe469c793a843999e7fc11bbc340a69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4226f0c9d4334a83befa090204f42284": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eef3dca547884d3cafb060b90ecac7e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e6d8b8606749403da65e930c02f78eb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6da62a68e7c4131abc290f7c3a199a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "54a1991337714e6d966a9b765b529c93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5ad51f7de9e24179a8f49b26c840ef6b",
              "IPY_MODEL_2fc52e61ffd94771a49062a3d4b7d5b7",
              "IPY_MODEL_bdc72d88a3064cfab5bc235e05c47bb1"
            ],
            "layout": "IPY_MODEL_f9ece16a3c884aa5b35e867cbc6789f3"
          }
        },
        "5ad51f7de9e24179a8f49b26c840ef6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03a096c5b6b74990add0d92a218c59b2",
            "placeholder": "​",
            "style": "IPY_MODEL_a97c899a52d947cf908acddec60532cf",
            "value": "Map: 100%"
          }
        },
        "2fc52e61ffd94771a49062a3d4b7d5b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3078ecd322a4dbead44a84360062fd3",
            "max": 150,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3cf6e71eee014f288590f47fa9d3defc",
            "value": 150
          }
        },
        "bdc72d88a3064cfab5bc235e05c47bb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e433dbb3de1b4120aeba9a2a1083bab0",
            "placeholder": "​",
            "style": "IPY_MODEL_f3df7c035ce44bbb80b06edc28e0662f",
            "value": " 150/150 [00:00&lt;00:00, 2038.01 examples/s]"
          }
        },
        "f9ece16a3c884aa5b35e867cbc6789f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03a096c5b6b74990add0d92a218c59b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a97c899a52d947cf908acddec60532cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3078ecd322a4dbead44a84360062fd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cf6e71eee014f288590f47fa9d3defc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e433dbb3de1b4120aeba9a2a1083bab0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3df7c035ce44bbb80b06edc28e0662f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}