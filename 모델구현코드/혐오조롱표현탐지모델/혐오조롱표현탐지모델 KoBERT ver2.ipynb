{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5054892678c547b49c1b1cbeed2ba75c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e7f293633fec45f7b473347c139a9bcc",
              "IPY_MODEL_2249b5dc4d924c49bc8523b75055a48e",
              "IPY_MODEL_71e77523004e4ac297e4d75cc82ca70b"
            ],
            "layout": "IPY_MODEL_95619b1327e1483a9fe83a17447e2a1a"
          }
        },
        "e7f293633fec45f7b473347c139a9bcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96969ab134b84d51b01f5483805ae7ab",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e20d5e3cc3094d489a9d430e698abbe2",
            "value": "Map:â€‡100%"
          }
        },
        "2249b5dc4d924c49bc8523b75055a48e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5881f8637d543a284e8d368b5221922",
            "max": 4160,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_01cf7f237372439287b20a59d49f1093",
            "value": 4160
          }
        },
        "71e77523004e4ac297e4d75cc82ca70b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d98871a86a94c2e9e059b40587fc45a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_73907acc6dbb43fa841f565e08ec7e6a",
            "value": "â€‡4160/4160â€‡[00:02&lt;00:00,â€‡1932.78â€‡examples/s]"
          }
        },
        "95619b1327e1483a9fe83a17447e2a1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96969ab134b84d51b01f5483805ae7ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e20d5e3cc3094d489a9d430e698abbe2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e5881f8637d543a284e8d368b5221922": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01cf7f237372439287b20a59d49f1093": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5d98871a86a94c2e9e059b40587fc45a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73907acc6dbb43fa841f565e08ec7e6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f933d95143374866be23ab7a8b8e7c1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_385a2071c3384228adb581923893b621",
              "IPY_MODEL_0c9007829ff541de957041de0a76e91a",
              "IPY_MODEL_d66625dd14784ea7914ee358cb0d961b"
            ],
            "layout": "IPY_MODEL_adc2b204046a438885a28baca1859aa4"
          }
        },
        "385a2071c3384228adb581923893b621": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b47825722acf40e08eeea251b6ec21d8",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_6d303727275146b991f5e8aad65dd180",
            "value": "Map:â€‡100%"
          }
        },
        "0c9007829ff541de957041de0a76e91a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de9e5a0b90114d728b5d7f9bbe2493f9",
            "max": 1040,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_309abf6c43504d2c86d6cdfa9e4a5365",
            "value": 1040
          }
        },
        "d66625dd14784ea7914ee358cb0d961b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd197657848f47d396691dd466642bbf",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_266a430bbde34d20a62001208c5fd967",
            "value": "â€‡1040/1040â€‡[00:00&lt;00:00,â€‡1920.74â€‡examples/s]"
          }
        },
        "adc2b204046a438885a28baca1859aa4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b47825722acf40e08eeea251b6ec21d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d303727275146b991f5e8aad65dd180": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de9e5a0b90114d728b5d7f9bbe2493f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "309abf6c43504d2c86d6cdfa9e4a5365": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bd197657848f47d396691dd466642bbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "266a430bbde34d20a62001208c5fd967": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_R8L8m8oEiEz",
        "outputId": "846842be-4f49-4ba2-9841-83a30bc405da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "import os, json, random, numpy as np, torch\n",
        "os.environ[\"HF_ALLOW_CODE_EXECUTION\"] = \"1\"\n",
        "os.environ[\"TRANSFORMERS_ALLOW_CODE_EXECUTION\"] = \"1\"\n",
        "cfg_path = os.path.expanduser(\"~/.huggingface/config.json\")\n",
        "os.makedirs(os.path.dirname(cfg_path), exist_ok=True)\n",
        "try:\n",
        "    with open(cfg_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump({\"transformers\": {\"allow_code_execution\": True}}, f)\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
        "set_seed(42)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install optuna\n",
        "from typing import List, Dict\n",
        "import re, pandas as pd, optuna\n",
        "from datasets import Dataset as HFDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoModelForSequenceClassification,\n",
        "    TrainingArguments, Trainer, DataCollatorWithPadding, EarlyStoppingCallback\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02mnlnCyFm_z",
        "outputId": "bbfa9813-0853-4c76-87d3-357596b84c76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/395.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m \u001b[32m389.1/395.9 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m395.9/395.9 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/247.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m247.0/247.0 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = \"/content/drive/MyDrive/metrics/í˜ì˜¤ì¡°ë¡±í‘œí˜„íƒì§€ìš©ë°ì´í„° 5400ê°œ.jsonl\""
      ],
      "metadata": {
        "id": "NJo-KEu2ElVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_jsonl(path: str):\n",
        "    rows = []\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for lineno, line in enumerate(f, start=1):\n",
        "            s = line.strip()\n",
        "            if not s:\n",
        "                continue\n",
        "            try:\n",
        "                rows.append(json.loads(s))\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"[WARN] JSON decode error at line {lineno}: {e}\")\n",
        "    return rows\n",
        "\n",
        "raw = load_jsonl(DATA_PATH)\n",
        "print(f\"âœ… ë¡œë“œ ì™„ë£Œ: {len(raw)} í–‰\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2aEwbdjFQNL",
        "outputId": "bb6dae68-81a7-4c85-d336-639fe77fadba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… ë¡œë“œ ì™„ë£Œ: 5200 í–‰\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def map_label(lbl: str) -> int:\n",
        "    if not lbl: return 0\n",
        "    return 1 if lbl.strip().lower() == \"toxic\" else 0"
      ],
      "metadata": {
        "id": "TjQGbwciGuL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEP = \" [SEP] \"\n",
        "def build_input(utterances: List[str], k: int, use_prof_feature: bool = False) -> str:\n",
        "    n = len(utterances)\n",
        "    target = utterances[k]\n",
        "    before = SEP.join(utterances[:k]) if k > 0 else \"\"\n",
        "    after  = SEP.join(utterances[k+1:]) if (k + 1) < n else \"\"\n",
        "\n",
        "    parts = []\n",
        "    if before:\n",
        "        parts.append(\"[CTX] \" + before)\n",
        "    parts.append(\"[TGT] \" + target + \" [/TGT]\")\n",
        "    if after:\n",
        "        parts.append(\"[CTX] \" + after)\n",
        "    return \"\\n\".join(parts)\n",
        "\n",
        "records = []\n",
        "bad = 0\n",
        "for r in raw:\n",
        "    utts = r.get(\"utterances\", [])\n",
        "    idx = r.get(\"target_index\", None)\n",
        "    lbl = r.get(\"label\", None)\n",
        "    if not isinstance(utts, list) or idx is None or idx < 0 or idx >= len(utts):\n",
        "        bad += 1; continue\n",
        "    records.append({\n",
        "        \"dialogue_id\": r.get(\"dialogue_id\", \"\"),\n",
        "        \"text\": build_input(utts, idx, use_prof_feature=False),\n",
        "        \"label\": map_label(lbl)\n",
        "    })\n",
        "if bad: print(f\"âš ï¸ ë¬´ì‹œëœ ë ˆì½”ë“œ: {bad}\")\n",
        "\n",
        "df = pd.DataFrame(records)\n",
        "print(df.head(2))\n",
        "print(\"ë¼ë²¨ ë¶„í¬:\\n\", df[\"label\"].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjkuSo2sGxBy",
        "outputId": "50944ca4-93bd-45ac-be78-29c083e728c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  dialogue_id                                               text  label\n",
            "0         001  [CTX] ë¶€ë´ë¶€ë´ ì™”ëŠ”ë° ì•„ë¬´ë„ ì•ˆì™”ë„¤. ì‹œê°„ê°œë…ë“¤ì´ ì—†ë„¤ [SEP] ë§ì•„. ì‚¬ëŒ...      1\n",
            "1         002  [CTX] ì¸ë°© ë³´ëŠ” ë‚¨ìëŠ” ê±°ë¥´ëŠ”ê²Œ ë§ë‹¤ [SEP] íŠ¹íˆ ë²—ë°©ë³´ëŠ” ì• ë“¤ì€ ì§„ì§œ ê±°...      0\n",
            "ë¼ë²¨ ë¶„í¬:\n",
            " label\n",
            "0    2946\n",
            "1    2254\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_tok_and_model():\n",
        "    try:\n",
        "        tok = AutoTokenizer.from_pretrained(\"monologg/kobert\", trust_remote_code=True)\n",
        "        mdl = AutoModelForSequenceClassification.from_pretrained(\n",
        "            \"monologg/kobert\", trust_remote_code=True, num_labels=2\n",
        "        )\n",
        "        print(\"âœ… KoBERT ë¡œë“œ\")\n",
        "    except Exception as e:\n",
        "        print(\"âŒ KoBERT ì‹¤íŒ¨ â†’ mBERTë¡œ ëŒ€ì²´:\", e)\n",
        "        tok = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "        mdl = AutoModelForSequenceClassification.from_pretrained(\n",
        "            \"bert-base-multilingual-cased\", num_labels=2\n",
        "        )\n",
        "        print(\"âœ… mBERT ë¡œë“œ\")\n",
        "    return tok, mdl\n",
        "\n",
        "tokenizer, base_model = load_tok_and_model()\n",
        "\n",
        "# KoBERT ì €ì¥ í˜¸í™˜ íŒ¨ì¹˜\n",
        "orig_save_vocabulary = getattr(tokenizer, \"save_vocabulary\", None)\n",
        "if callable(orig_save_vocabulary):\n",
        "    def _patched_save_vocabulary(save_directory, *args, **kwargs):\n",
        "        return orig_save_vocabulary(save_directory)\n",
        "    tokenizer.save_vocabulary = _patched_save_vocabulary\n",
        "\n",
        "base_model.to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWA6ExyZGx8a",
        "outputId": "2138e283-980f-46a5-d5d6-d1d536a3c842"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… KoBERT ë¡œë“œ\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(8002, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 320  # HPOì—ì„œëŠ” ê³ ì •(ì‹œí€€ìŠ¤ ê¸¸ì´ëŠ” ì¬í† í¬ë‚˜ì´ì¦ˆê°€ í•„ìš”í•´ ë¹„ê¶Œì¥)\n",
        "def tokenize_fn(batch):\n",
        "    return tokenizer(batch[\"text\"], truncation=True, padding=False, max_length=MAX_LEN)\n",
        "\n",
        "train_df, val_df = train_test_split(\n",
        "    df, test_size=0.2, random_state=42, stratify=df[\"label\"]\n",
        ")\n",
        "\n",
        "train_ds = HFDataset.from_pandas(train_df.reset_index(drop=True))\n",
        "val_ds   = HFDataset.from_pandas(val_df.reset_index(drop=True))\n",
        "train_ds = train_ds.map(tokenize_fn, batched=True, remove_columns=[\"text\", \"dialogue_id\"])\n",
        "val_ds   = val_ds.map(tokenize_fn,   batched=True, remove_columns=[\"text\", \"dialogue_id\"])\n",
        "train_ds = train_ds.rename_column(\"label\", \"labels\")\n",
        "val_ds   = val_ds.rename_column(\"label\", \"labels\")\n",
        "train_ds.set_format(type=\"torch\"); val_ds.set_format(type=\"torch\")\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "5054892678c547b49c1b1cbeed2ba75c",
            "e7f293633fec45f7b473347c139a9bcc",
            "2249b5dc4d924c49bc8523b75055a48e",
            "71e77523004e4ac297e4d75cc82ca70b",
            "95619b1327e1483a9fe83a17447e2a1a",
            "96969ab134b84d51b01f5483805ae7ab",
            "e20d5e3cc3094d489a9d430e698abbe2",
            "e5881f8637d543a284e8d368b5221922",
            "01cf7f237372439287b20a59d49f1093",
            "5d98871a86a94c2e9e059b40587fc45a",
            "73907acc6dbb43fa841f565e08ec7e6a",
            "f933d95143374866be23ab7a8b8e7c1d",
            "385a2071c3384228adb581923893b621",
            "0c9007829ff541de957041de0a76e91a",
            "d66625dd14784ea7914ee358cb0d961b",
            "adc2b204046a438885a28baca1859aa4",
            "b47825722acf40e08eeea251b6ec21d8",
            "6d303727275146b991f5e8aad65dd180",
            "de9e5a0b90114d728b5d7f9bbe2493f9",
            "309abf6c43504d2c86d6cdfa9e4a5365",
            "bd197657848f47d396691dd466642bbf",
            "266a430bbde34d20a62001208c5fd967"
          ]
        },
        "id": "x17w0HN_G7Pa",
        "outputId": "14495392-2481-4aa2-d51d-1962f5d7bebc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/4160 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5054892678c547b49c1b1cbeed2ba75c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1040 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f933d95143374866be23ab7a8b8e7c1d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = logits.argmax(axis=-1)\n",
        "    out = {\n",
        "        \"accuracy\": accuracy_score(labels, preds),\n",
        "        \"precision\": precision_score(labels, preds, zero_division=0),\n",
        "        \"recall\": recall_score(labels, preds, zero_division=0),\n",
        "        \"f1\": f1_score(labels, preds, zero_division=0),\n",
        "    }\n",
        "    try:\n",
        "        prob_pos = torch.softmax(torch.tensor(logits), dim=-1)[:, 1].numpy()\n",
        "        out[\"roc_auc\"] = roc_auc_score(labels, prob_pos)\n",
        "    except Exception:\n",
        "        out[\"roc_auc\"] = float(\"nan\")\n",
        "    return out"
      ],
      "metadata": {
        "id": "35EVpsKDG9Py"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hp_space(trial):\n",
        "    return {\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 5e-4, log=True),\n",
        "        \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [8, 16, 32]),\n",
        "        \"per_device_eval_batch_size\": trial.suggest_categorical(\"per_device_eval_batch_size\", [8, 16, 32]),\n",
        "        \"gradient_accumulation_steps\": trial.suggest_categorical(\"gradient_accumulation_steps\", [1, 2, 4]),\n",
        "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 0.0, 0.05),\n",
        "        \"warmup_ratio\": trial.suggest_float(\"warmup_ratio\", 0.0, 0.2),\n",
        "        \"lr_scheduler_type\": trial.suggest_categorical(\n",
        "            \"lr_scheduler_type\", [\"linear\", \"cosine\", \"cosine_with_restarts\", \"polynomial\"]\n",
        "        ),\n",
        "        \"num_train_epochs\": 2,  # íƒìƒ‰ì€ ê°€ë³ê²Œ\n",
        "    }"
      ],
      "metadata": {
        "id": "IeKG87abHBri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_objective(metrics):  # ìµœëŒ€í™” ëª©í‘œ\n",
        "    return metrics[\"eval_f1\"]"
      ],
      "metadata": {
        "id": "D-m6QrB9McFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_init():\n",
        "    # ê° trialë§ˆë‹¤ ìƒˆ ëª¨ë¸ (ê°™ì€ ì•„í‚¤í…ì²˜ ì¬ì´ˆê¸°í™”)\n",
        "    m = AutoModelForSequenceClassification.from_pretrained(\n",
        "        \"monologg/kobert\", trust_remote_code=True, num_labels=2\n",
        "    )\n",
        "    return m\n",
        "\n",
        "args_hpo = TrainingArguments(\n",
        "    output_dir=\"./hpo_tmp\",\n",
        "    logging_dir=\"./hpo_tmp/logs\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_strategy=\"epoch\",\n",
        "    logging_steps=1,\n",
        "    logging_first_step=True,\n",
        "    report_to=[],\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    load_best_model_at_end=False,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    greater_is_better=True,\n",
        "    disable_tqdm=False,\n",
        ")\n",
        "\n",
        "trainer_hpo = Trainer(\n",
        "    model_init=model_init,\n",
        "    args=args_hpo,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=val_ds,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4f9MSBDMeqF",
        "outputId": "f0cce82a-8a28-417e-d1e0-d9209a4bed76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-533537757.py:24: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer_hpo = Trainer(\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ğŸ” HPO ì‹œì‘ (n_trials=20)\")\n",
        "best_run = trainer_hpo.hyperparameter_search(\n",
        "    direction=\"maximize\",\n",
        "    hp_space=hp_space,\n",
        "    compute_objective=compute_objective,\n",
        "    n_trials=20,\n",
        "    backend=\"optuna\"\n",
        ")\n",
        "print(\"âœ… Best trial:\", best_run)\n",
        "print(\"â¡ï¸ Best params:\", best_run.hyperparameters)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vkNM4tpTHEmR",
        "outputId": "29da9185-8a44-4e55-a630-986e88796117"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-13 06:58:06,550] A new study created in memory with name: no-name-3598d132-29f4-4ed9-8633-47300f0a374b\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ” HPO ì‹œì‘ (n_trials=20)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='260' max='260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [260/260 00:31, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Roc Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.272400</td>\n",
              "      <td>0.184468</td>\n",
              "      <td>0.935577</td>\n",
              "      <td>0.870656</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.930857</td>\n",
              "      <td>0.981831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.141300</td>\n",
              "      <td>0.141703</td>\n",
              "      <td>0.950962</td>\n",
              "      <td>0.914938</td>\n",
              "      <td>0.977827</td>\n",
              "      <td>0.945338</td>\n",
              "      <td>0.985497</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-13 06:58:39,479] Trial 0 finished with value: 0.9453376205787781 and parameters: {'learning_rate': 6.456603442172581e-05, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 32, 'gradient_accumulation_steps': 2, 'weight_decay': 0.015790742975545096, 'warmup_ratio': 0.030977973524302805, 'lr_scheduler_type': 'cosine_with_restarts'}. Best is trial 0 with value: 0.9453376205787781.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='520' max='520' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [520/520 00:33, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Roc Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.622900</td>\n",
              "      <td>0.688558</td>\n",
              "      <td>0.566346</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.505827</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.696000</td>\n",
              "      <td>0.684475</td>\n",
              "      <td>0.566346</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.510106</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-13 06:59:14,461] Trial 1 finished with value: 0.0 and parameters: {'learning_rate': 0.00036171387440645046, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 32, 'gradient_accumulation_steps': 1, 'weight_decay': 0.0026924270846941213, 'warmup_ratio': 0.15443344903804587, 'lr_scheduler_type': 'linear'}. Best is trial 0 with value: 0.9453376205787781.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='260' max='260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [260/260 00:53, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Roc Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.328800</td>\n",
              "      <td>0.193970</td>\n",
              "      <td>0.945192</td>\n",
              "      <td>0.905350</td>\n",
              "      <td>0.975610</td>\n",
              "      <td>0.939168</td>\n",
              "      <td>0.970957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.191600</td>\n",
              "      <td>0.159057</td>\n",
              "      <td>0.952885</td>\n",
              "      <td>0.910204</td>\n",
              "      <td>0.988914</td>\n",
              "      <td>0.947928</td>\n",
              "      <td>0.971804</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-13 07:00:09,388] Trial 2 finished with value: 0.9479277364505845 and parameters: {'learning_rate': 0.00013960832795509835, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 32, 'gradient_accumulation_steps': 4, 'weight_decay': 0.019846607846760223, 'warmup_ratio': 0.11385657098516477, 'lr_scheduler_type': 'linear'}. Best is trial 2 with value: 0.9479277364505845.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='260' max='260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [260/260 00:21, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Roc Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.306400</td>\n",
              "      <td>0.163696</td>\n",
              "      <td>0.952885</td>\n",
              "      <td>0.905242</td>\n",
              "      <td>0.995565</td>\n",
              "      <td>0.948258</td>\n",
              "      <td>0.974012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.167700</td>\n",
              "      <td>0.144425</td>\n",
              "      <td>0.953846</td>\n",
              "      <td>0.908722</td>\n",
              "      <td>0.993348</td>\n",
              "      <td>0.949153</td>\n",
              "      <td>0.980374</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-13 07:00:32,263] Trial 3 finished with value: 0.9491525423728814 and parameters: {'learning_rate': 1.8066216260075222e-05, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 16, 'gradient_accumulation_steps': 1, 'weight_decay': 0.017515971750933928, 'warmup_ratio': 0.018798604786228523, 'lr_scheduler_type': 'polynomial'}. Best is trial 3 with value: 0.9491525423728814.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1040' max='1040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1040/1040 01:03, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Roc Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.657200</td>\n",
              "      <td>0.688273</td>\n",
              "      <td>0.566346</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.582900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.693900</td>\n",
              "      <td>0.685354</td>\n",
              "      <td>0.566346</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.611817</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-13 07:01:37,438] Trial 4 finished with value: 0.0 and parameters: {'learning_rate': 0.00023147169359311382, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'gradient_accumulation_steps': 1, 'weight_decay': 0.022720502145482126, 'warmup_ratio': 0.10697183713977375, 'lr_scheduler_type': 'cosine_with_restarts'}. Best is trial 3 with value: 0.9491525423728814.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='130' max='260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [130/260 00:25 < 00:25, 5.11 it/s, Epoch 1/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Roc Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.609900</td>\n",
              "      <td>0.696232</td>\n",
              "      <td>0.433654</td>\n",
              "      <td>0.433654</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.604963</td>\n",
              "      <td>0.422058</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-13 07:02:03,344] Trial 5 pruned. \n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1040' max='1040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1040/1040 01:03, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Roc Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.678000</td>\n",
              "      <td>0.692292</td>\n",
              "      <td>0.437500</td>\n",
              "      <td>0.435328</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.606590</td>\n",
              "      <td>0.922193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.697000</td>\n",
              "      <td>0.684686</td>\n",
              "      <td>0.566346</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.585840</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-13 07:03:08,211] Trial 6 finished with value: 0.0 and parameters: {'learning_rate': 0.00034095415290848067, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'gradient_accumulation_steps': 1, 'weight_decay': 0.019779108701849936, 'warmup_ratio': 0.1556521493749824, 'lr_scheduler_type': 'polynomial'}. Best is trial 3 with value: 0.9491525423728814.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1040' max='1040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1040/1040 01:00, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Roc Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.301100</td>\n",
              "      <td>0.193222</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.874031</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.932782</td>\n",
              "      <td>0.980549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.169700</td>\n",
              "      <td>0.155555</td>\n",
              "      <td>0.957692</td>\n",
              "      <td>0.917864</td>\n",
              "      <td>0.991131</td>\n",
              "      <td>0.953092</td>\n",
              "      <td>0.984470</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-13 07:04:10,219] Trial 7 finished with value: 0.9530916844349681 and parameters: {'learning_rate': 3.371231230528883e-05, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 32, 'gradient_accumulation_steps': 1, 'weight_decay': 0.028357515375541816, 'warmup_ratio': 0.10904626443293292, 'lr_scheduler_type': 'linear'}. Best is trial 7 with value: 0.9530916844349681.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1040' max='1040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1040/1040 01:03, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Roc Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.476000</td>\n",
              "      <td>0.484088</td>\n",
              "      <td>0.853846</td>\n",
              "      <td>0.874687</td>\n",
              "      <td>0.773836</td>\n",
              "      <td>0.821176</td>\n",
              "      <td>0.856128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.440000</td>\n",
              "      <td>0.415385</td>\n",
              "      <td>0.853846</td>\n",
              "      <td>0.874687</td>\n",
              "      <td>0.773836</td>\n",
              "      <td>0.821176</td>\n",
              "      <td>0.844473</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-13 07:05:15,138] Trial 8 finished with value: 0.8211764705882353 and parameters: {'learning_rate': 0.0002821978534124849, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 8, 'gradient_accumulation_steps': 1, 'weight_decay': 0.03689766552256707, 'warmup_ratio': 0.10685811187878776, 'lr_scheduler_type': 'cosine'}. Best is trial 7 with value: 0.9530916844349681.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='130' max='130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [130/130 00:20, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Roc Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.314500</td>\n",
              "      <td>0.222168</td>\n",
              "      <td>0.938462</td>\n",
              "      <td>0.905660</td>\n",
              "      <td>0.957871</td>\n",
              "      <td>0.931034</td>\n",
              "      <td>0.976557</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.169300</td>\n",
              "      <td>0.143074</td>\n",
              "      <td>0.950962</td>\n",
              "      <td>0.909836</td>\n",
              "      <td>0.984479</td>\n",
              "      <td>0.945687</td>\n",
              "      <td>0.979679</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-13 07:05:36,738] Trial 9 finished with value: 0.9456869009584664 and parameters: {'learning_rate': 9.299420349578542e-05, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 16, 'gradient_accumulation_steps': 2, 'weight_decay': 0.04784454975986293, 'warmup_ratio': 0.13036066165982632, 'lr_scheduler_type': 'cosine_with_restarts'}. Best is trial 7 with value: 0.9530916844349681.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='130' max='260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [130/260 00:14 < 00:14, 8.90 it/s, Epoch 1/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Roc Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.360500</td>\n",
              "      <td>0.184566</td>\n",
              "      <td>0.935577</td>\n",
              "      <td>0.912017</td>\n",
              "      <td>0.942350</td>\n",
              "      <td>0.926936</td>\n",
              "      <td>0.974712</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-13 07:05:51,933] Trial 10 pruned. \n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='260' max='260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [260/260 00:21, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Roc Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.351400</td>\n",
              "      <td>0.188399</td>\n",
              "      <td>0.948077</td>\n",
              "      <td>0.896208</td>\n",
              "      <td>0.995565</td>\n",
              "      <td>0.943277</td>\n",
              "      <td>0.967439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.187800</td>\n",
              "      <td>0.164067</td>\n",
              "      <td>0.952885</td>\n",
              "      <td>0.903614</td>\n",
              "      <td>0.997783</td>\n",
              "      <td>0.948367</td>\n",
              "      <td>0.974546</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-13 07:06:14,913] Trial 11 finished with value: 0.9483667017913593 and parameters: {'learning_rate': 1.0671851380287005e-05, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 16, 'gradient_accumulation_steps': 1, 'weight_decay': 0.02955851045847388, 'warmup_ratio': 0.0055462790409018525, 'lr_scheduler_type': 'polynomial'}. Best is trial 7 with value: 0.9530916844349681.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='130' max='260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [130/260 00:09 < 00:09, 13.62 it/s, Epoch 1/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Roc Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.306200</td>\n",
              "      <td>0.181126</td>\n",
              "      <td>0.943269</td>\n",
              "      <td>0.913502</td>\n",
              "      <td>0.960089</td>\n",
              "      <td>0.936216</td>\n",
              "      <td>0.977236</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-13 07:06:25,061] Trial 12 pruned. \n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='130' max='260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [130/260 00:09 < 00:09, 13.90 it/s, Epoch 1/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Roc Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.319100</td>\n",
              "      <td>0.178023</td>\n",
              "      <td>0.945192</td>\n",
              "      <td>0.887795</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.940563</td>\n",
              "      <td>0.976114</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-13 07:06:35,059] Trial 13 pruned. \n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [66/66 00:19, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Roc Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.413800</td>\n",
              "      <td>0.201495</td>\n",
              "      <td>0.945192</td>\n",
              "      <td>0.894000</td>\n",
              "      <td>0.991131</td>\n",
              "      <td>0.940063</td>\n",
              "      <td>0.966214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.189700</td>\n",
              "      <td>0.164580</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.903030</td>\n",
              "      <td>0.991131</td>\n",
              "      <td>0.945032</td>\n",
              "      <td>0.970705</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-13 07:06:56,250] Trial 14 finished with value: 0.945031712473573 and parameters: {'learning_rate': 4.091488397527725e-05, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 16, 'gradient_accumulation_steps': 4, 'weight_decay': 0.04286827415881622, 'warmup_ratio': 0.030374957672054226, 'lr_scheduler_type': 'polynomial'}. Best is trial 7 with value: 0.9530916844349681.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1040' max='1040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1040/1040 01:01, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Roc Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.309600</td>\n",
              "      <td>0.233646</td>\n",
              "      <td>0.924038</td>\n",
              "      <td>0.850943</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.919470</td>\n",
              "      <td>0.974763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.186800</td>\n",
              "      <td>0.169828</td>\n",
              "      <td>0.951923</td>\n",
              "      <td>0.905051</td>\n",
              "      <td>0.993348</td>\n",
              "      <td>0.947146</td>\n",
              "      <td>0.978990</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-13 07:07:58,907] Trial 15 finished with value: 0.9471458773784355 and parameters: {'learning_rate': 1.0627587115877893e-05, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 32, 'gradient_accumulation_steps': 1, 'weight_decay': 0.028145722365509745, 'warmup_ratio': 0.0905156257741506, 'lr_scheduler_type': 'linear'}. Best is trial 7 with value: 0.9530916844349681.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='260' max='260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [260/260 00:21, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Roc Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.304300</td>\n",
              "      <td>0.169548</td>\n",
              "      <td>0.950962</td>\n",
              "      <td>0.901606</td>\n",
              "      <td>0.995565</td>\n",
              "      <td>0.946259</td>\n",
              "      <td>0.969858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.174200</td>\n",
              "      <td>0.155420</td>\n",
              "      <td>0.953846</td>\n",
              "      <td>0.905433</td>\n",
              "      <td>0.997783</td>\n",
              "      <td>0.949367</td>\n",
              "      <td>0.976628</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-13 07:08:21,699] Trial 16 finished with value: 0.9493670886075949 and parameters: {'learning_rate': 1.5379143973514842e-05, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 16, 'gradient_accumulation_steps': 1, 'weight_decay': 0.0361629662567273, 'warmup_ratio': 0.0004946233867199751, 'lr_scheduler_type': 'polynomial'}. Best is trial 7 with value: 0.9530916844349681.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1040' max='1040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1040/1040 01:01, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Roc Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.319500</td>\n",
              "      <td>0.171146</td>\n",
              "      <td>0.943269</td>\n",
              "      <td>0.885827</td>\n",
              "      <td>0.997783</td>\n",
              "      <td>0.938478</td>\n",
              "      <td>0.973387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.178100</td>\n",
              "      <td>0.163205</td>\n",
              "      <td>0.953846</td>\n",
              "      <td>0.913758</td>\n",
              "      <td>0.986696</td>\n",
              "      <td>0.948827</td>\n",
              "      <td>0.977187</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-13 07:09:24,828] Trial 17 finished with value: 0.9488272921108742 and parameters: {'learning_rate': 5.150036651993096e-05, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 16, 'gradient_accumulation_steps': 1, 'weight_decay': 0.03851189210778395, 'warmup_ratio': 0.1441542230467301, 'lr_scheduler_type': 'cosine'}. Best is trial 7 with value: 0.9530916844349681.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='130' max='130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [130/130 00:19, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Roc Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.460500</td>\n",
              "      <td>0.226962</td>\n",
              "      <td>0.944231</td>\n",
              "      <td>0.896970</td>\n",
              "      <td>0.984479</td>\n",
              "      <td>0.938689</td>\n",
              "      <td>0.967064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.212600</td>\n",
              "      <td>0.178286</td>\n",
              "      <td>0.950962</td>\n",
              "      <td>0.904858</td>\n",
              "      <td>0.991131</td>\n",
              "      <td>0.946032</td>\n",
              "      <td>0.972747</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-13 07:09:45,626] Trial 18 finished with value: 0.946031746031746 and parameters: {'learning_rate': 1.6350311192495442e-05, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 32, 'gradient_accumulation_steps': 2, 'weight_decay': 0.0305409740457476, 'warmup_ratio': 0.05133250986092022, 'lr_scheduler_type': 'linear'}. Best is trial 7 with value: 0.9530916844349681.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='65' max='130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 65/130 00:15 < 00:15, 4.17 it/s, Epoch 1/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Roc Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.366100</td>\n",
              "      <td>0.223445</td>\n",
              "      <td>0.920192</td>\n",
              "      <td>0.844569</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.915736</td>\n",
              "      <td>0.967601</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-13 07:10:01,631] Trial 19 pruned. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Best trial: BestRun(run_id='7', objective=0.9530916844349681, hyperparameters={'learning_rate': 3.371231230528883e-05, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 32, 'gradient_accumulation_steps': 1, 'weight_decay': 0.028357515375541816, 'warmup_ratio': 0.10904626443293292, 'lr_scheduler_type': 'linear'}, run_summary=None)\n",
            "â¡ï¸ Best params: {'learning_rate': 3.371231230528883e-05, 'per_device_train_batch_size': 8, 'per_device_eval_batch_size': 32, 'gradient_accumulation_steps': 1, 'weight_decay': 0.028357515375541816, 'warmup_ratio': 0.10904626443293292, 'lr_scheduler_type': 'linear'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best = best_run.hyperparameters\n",
        "\n",
        "pos = int((train_df[\"label\"] == 1).sum())\n",
        "neg = int((train_df[\"label\"] == 0).sum())\n",
        "w_neg = 1.0\n",
        "w_pos = float(neg / pos) if pos > 0 else 1.0\n",
        "class_weights = torch.tensor([w_neg, w_pos], dtype=torch.float32)\n",
        "if torch.cuda.is_available():\n",
        "    class_weights = class_weights.cuda()\n",
        "\n",
        "def custom_compute_loss(model, inputs, return_outputs=False, **kwargs):\n",
        "    labels = inputs.get(\"labels\")\n",
        "    outputs = model(**{k: v for k, v in inputs.items() if k != \"labels\"})\n",
        "    logits = outputs.logits\n",
        "    loss = torch.nn.CrossEntropyLoss(weight=class_weights)(logits.view(-1, 2), labels.view(-1))\n",
        "    return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "args_final = TrainingArguments(\n",
        "    output_dir=\"./results_ctx_tgt\",\n",
        "    logging_dir=\"./results_ctx_tgt/logs\",\n",
        "    num_train_epochs=4,  # ìµœì¢…ì€ ë” ê¸¸ê²Œ(í•„ìš”ì‹œ ì¡°ì ˆ)\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=2,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    greater_is_better=True,\n",
        "    report_to=[],\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    dataloader_pin_memory=False,\n",
        "    **best,  # HPOë¡œ ì°¾ì€ ìµœì ê°’ ì£¼ì… (lr, batch, gaccum, wd, warmup, scheduler ë“±)\n",
        ")\n"
      ],
      "metadata": {
        "id": "jrJRtdCfMuF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"monologg/kobert\", trust_remote_code=True, num_labels=2\n",
        ").to(device)\n",
        "\n",
        "trainer_final = Trainer(\n",
        "    model=final_model,\n",
        "    args=args_final,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=val_ds,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
        ")\n",
        "trainer_final.compute_loss = custom_compute_loss\n",
        "\n",
        "print(\"ğŸš€ ìµœì¢… ì¬í•™ìŠµ ì‹œì‘\")\n",
        "trainer_final.train()\n",
        "print(\"âœ… ì¬í•™ìŠµ ì™„ë£Œ\")\n",
        "\n",
        "eval_out = trainer_final.evaluate()\n",
        "print(\"ğŸ“Š ìµœì¢… ê²€ì¦ ì§€í‘œ:\", eval_out)\n",
        "\n",
        "# ì €ì¥\n",
        "trainer_final.save_model(\"./results_ctx_tgt/best\")\n",
        "tokenizer.save_pretrained(\"./results_ctx_tgt/best\")\n",
        "print(\"ğŸ’¾ ì €ì¥ ì™„ë£Œ: ./results_ctx_tgt/best\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "zd6ARE2NMuld",
        "outputId": "766cddb5-e1bb-4d7d-d593-762d5b44e22b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-2991758581.py:5: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer_final = Trainer(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ ìµœì¢… ì¬í•™ìŠµ ì‹œì‘\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2080' max='2080' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2080/2080 02:07, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Roc Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.308600</td>\n",
              "      <td>0.154942</td>\n",
              "      <td>0.951923</td>\n",
              "      <td>0.901804</td>\n",
              "      <td>0.997783</td>\n",
              "      <td>0.947368</td>\n",
              "      <td>0.981699</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.200800</td>\n",
              "      <td>0.189484</td>\n",
              "      <td>0.948077</td>\n",
              "      <td>0.894632</td>\n",
              "      <td>0.997783</td>\n",
              "      <td>0.943396</td>\n",
              "      <td>0.981616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.152300</td>\n",
              "      <td>0.139709</td>\n",
              "      <td>0.955769</td>\n",
              "      <td>0.914110</td>\n",
              "      <td>0.991131</td>\n",
              "      <td>0.951064</td>\n",
              "      <td>0.985367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.096500</td>\n",
              "      <td>0.259440</td>\n",
              "      <td>0.940385</td>\n",
              "      <td>0.927473</td>\n",
              "      <td>0.935698</td>\n",
              "      <td>0.931567</td>\n",
              "      <td>0.984968</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… ì¬í•™ìŠµ ì™„ë£Œ\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [33/33 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“Š ìµœì¢… ê²€ì¦ ì§€í‘œ: {'eval_loss': 0.13970865309238434, 'eval_accuracy': 0.9557692307692308, 'eval_precision': 0.9141104294478528, 'eval_recall': 0.991130820399113, 'eval_f1': 0.951063829787234, 'eval_roc_auc': 0.985367359461525, 'eval_runtime': 0.7863, 'eval_samples_per_second': 1322.71, 'eval_steps_per_second': 41.971, 'epoch': 4.0}\n",
            "ğŸ’¾ ì €ì¥ ì™„ë£Œ: ./results_ctx_tgt/best\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Google Drive ê²½ë¡œ (ë¯¸ë¦¬ Drive ë§ˆìš´íŠ¸ ë˜ì–´ ìˆì–´ì•¼ í•¨)\n",
        "drive_path = \"/content/drive/MyDrive/model_backup/results_ctx_tgt_best\"\n",
        "\n",
        "# ëª¨ë¸ í´ë” ë³µì‚¬\n",
        "shutil.copytree(\"./results_ctx_tgt/best\", drive_path, dirs_exist_ok=True)\n",
        "\n",
        "print(f\"ğŸ“¦ ëª¨ë¸ì„ Google Driveë¡œ ë³µì‚¬ ì™„ë£Œ: {drive_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04ZBlPaUNjIk",
        "outputId": "5405a37f-8ff9-447c-a230-704b0795a65d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“¦ ëª¨ë¸ì„ Google Driveë¡œ ë³µì‚¬ ì™„ë£Œ: /content/drive/MyDrive/model_backup/results_ctx_tgt_best\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "SEP = \" [SEP] \"\n",
        "\n",
        "def build_input_from_lines(lines):\n",
        "    \"\"\"\n",
        "    lines: ì‚¬ìš©ìê°€ ì…ë ¥í•œ ë¬¸ì¥ ë¦¬ìŠ¤íŠ¸ (A â†’ B â†’ A â†’ ... â†’ B)\n",
        "    ë§ˆì§€ë§‰ ì¤„ì„ [TGT]ë¡œ ê°ì‹¸ê³ , ì•ë’¤ ë¬¸ë§¥ì€ [CTX]ë¡œ êµ¬ì„±\n",
        "    \"\"\"\n",
        "    assert len(lines) >= 2, \"ìµœì†Œ 2ì¤„ ì´ìƒ ì…ë ¥í•˜ì„¸ìš”.\"\n",
        "    k = len(lines) - 1\n",
        "    before = SEP.join(lines[:k])\n",
        "    target = lines[k]\n",
        "    parts = []\n",
        "    if before:\n",
        "        parts.append(\"[CTX] \" + before)\n",
        "    parts.append(\"[TGT] \" + target + \" [/TGT]\")\n",
        "    return \"\\n\".join(parts), target\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_last_line(\n",
        "    lines,\n",
        "    model,\n",
        "    tokenizer,\n",
        "    max_len=320,\n",
        "    device=None,\n",
        "    return_probs=True\n",
        "):\n",
        "    \"\"\"\n",
        "    linesì˜ ë§ˆì§€ë§‰ ë¬¸ì¥ì„ íƒ€ê¹ƒìœ¼ë¡œ íŒì •.\n",
        "    return: dict(label, prob_toxic, prob_non_toxic, target_text, input_text)\n",
        "      - label: 0=ë¹„ìœ í•´, 1=ìœ í•´(toxic)\n",
        "    \"\"\"\n",
        "    if device is None:\n",
        "        device = next(model.parameters()).device\n",
        "    model.eval()\n",
        "\n",
        "    input_text, target_text = build_input_from_lines(lines)\n",
        "    enc = tokenizer(\n",
        "        input_text,\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=max_len,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    enc = {k: v.to(device) for k, v in enc.items()}\n",
        "\n",
        "    out = model(**enc)\n",
        "    logits = out.logits\n",
        "    probs = torch.softmax(logits, dim=-1)[0].tolist()\n",
        "    pred = int(torch.argmax(logits, dim=-1).item())\n",
        "\n",
        "    res = {\n",
        "        \"label\": pred,  # 0=ë¹„ìœ í•´, 1=ìœ í•´\n",
        "        \"prob_non_toxic\": float(probs[0]),\n",
        "        \"prob_toxic\": float(probs[1]),\n",
        "        \"target_text\": target_text,\n",
        "        \"input_text\": input_text\n",
        "    }\n",
        "    if not return_probs:\n",
        "        del res[\"prob_non_toxic\"]; del res[\"prob_toxic\"]\n",
        "    return res\n",
        "\n",
        "def interactive_predict_last_line(model, tokenizer, max_len=320):\n",
        "    \"\"\"\n",
        "    ì½˜ì†”ì—ì„œ í•œ ì¤„ì”© ì…ë ¥ â†’ ë¹ˆ ì¤„ë¡œ ì¢…ë£Œ â†’ ë§ˆì§€ë§‰ ì¤„ íŒì •\n",
        "    \"\"\"\n",
        "    print(\"ì±„íŒ…ì„ í•œ ì¤„ì”© ì…ë ¥í•˜ì„¸ìš”. (ë¹ˆ ì¤„ ì…ë ¥ ì‹œ ì¢…ë£Œ)\\nì˜ˆ: A: ... â†’ B: ... â†’ A: ... â†’ B: ...\")\n",
        "    lines = []\n",
        "    while True:\n",
        "        line = input()\n",
        "        if not line.strip():\n",
        "            break\n",
        "        lines.append(line.strip())\n",
        "\n",
        "    if len(lines) < 2:\n",
        "        raise ValueError(\"ìµœì†Œ 2ì¤„ ì´ìƒ ì…ë ¥í•´ì•¼ í•©ë‹ˆë‹¤.\")\n",
        "\n",
        "    res = predict_last_line(lines, model, tokenizer, max_len=max_len)\n",
        "    print(\"\\nğŸ¯ íŒì • ê²°ê³¼\")\n",
        "    print(f\"- íƒ€ê¹ƒ ë¬¸ì¥: {res['target_text']}\")\n",
        "    print(f\"- ë¼ë²¨: {'ìœ í•´(1)' if res['label']==1 else 'ë¹„ìœ í•´(0)'}\")\n",
        "    print(f\"- prob_toxic: {res['prob_toxic']:.3f} | prob_non_toxic: {res['prob_non_toxic']:.3f}\")\n",
        "    return res\n"
      ],
      "metadata": {
        "id": "RLUPJ_gSJO1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) í™˜ê²½ë³€ìˆ˜(í˜„ì¬ ì„¸ì…˜ ì¦‰ì‹œ ë°˜ì˜)\n",
        "import os, json\n",
        "os.environ[\"HF_ALLOW_CODE_EXECUTION\"] = \"1\"            # ê³¼ê±° í‚¤\n",
        "os.environ[\"TRANSFORMERS_ALLOW_CODE_EXECUTION\"] = \"1\"  # í˜„ì¬ í‚¤\n",
        "\n",
        "# 2) ì „ì—­ ì„¤ì • íŒŒì¼ì„ ìˆ˜ë™ ìƒì„± (ë‹¤ìŒ ì„¸ì…˜ë¶€í„°ë„ ìë™ í—ˆìš©)\n",
        "cfg_path = os.path.expanduser(\"~/.huggingface/config.json\")\n",
        "os.makedirs(os.path.dirname(cfg_path), exist_ok=True)\n",
        "cfg = {\"transformers\": {\"allow_code_execution\": True}}\n",
        "with open(cfg_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(cfg, f)\n",
        "print(\"Wrote:\", cfg_path)\n",
        "print(open(cfg_path, \"r\", encoding=\"utf-8\").read())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHcfT4abKT4m",
        "outputId": "3b11328b-69a5-4f3e-9716-a115b9b876a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote: /root/.huggingface/config.json\n",
            "{\"transformers\": {\"allow_code_execution\": true}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "\n",
        "SAVE_DIR = \"./results_ctx_tgt/best\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    SAVE_DIR, trust_remote_code=True, local_files_only=True\n",
        ")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    SAVE_DIR, trust_remote_code=True, local_files_only=True\n",
        ")\n",
        "model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "interactive_predict_last_line(model, tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHh-ym3zJIaY",
        "outputId": "bdd4b6cb-bad6-4a87-ba83-1a6555948b7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì±„íŒ…ì„ í•œ ì¤„ì”© ì…ë ¥í•˜ì„¸ìš”. (ë¹ˆ ì¤„ ì…ë ¥ ì‹œ ì¢…ë£Œ)\n",
            "ì˜ˆ: A: ... â†’ B: ... â†’ A: ... â†’ B: ...\n",
            "ã…‹ã…‹ã…‹ã…‹ã…‹ê°œì›ƒê¸°ë‹¤\n",
            "ì´ê±° ë¨¸ì„ã…‹ã…‹ã…‹ã…‹ã…‹ ë‚˜ë„ ë³´ë‚´ì¤˜\n",
            "\n",
            "\n",
            "ğŸ¯ íŒì • ê²°ê³¼\n",
            "- íƒ€ê¹ƒ ë¬¸ì¥: ì´ê±° ë¨¸ì„ã…‹ã…‹ã…‹ã…‹ã…‹ ë‚˜ë„ ë³´ë‚´ì¤˜\n",
            "- ë¼ë²¨: ìœ í•´(1)\n",
            "- prob_toxic: 0.905 | prob_non_toxic: 0.095\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': 1,\n",
              " 'prob_non_toxic': 0.09483423084020615,\n",
              " 'prob_toxic': 0.9051657319068909,\n",
              " 'target_text': 'ì´ê±° ë¨¸ì„ã…‹ã…‹ã…‹ã…‹ã…‹ ë‚˜ë„ ë³´ë‚´ì¤˜',\n",
              " 'input_text': '[CTX] ã…‹ã…‹ã…‹ã…‹ã…‹ê°œì›ƒê¸°ë‹¤\\n[TGT] ì´ê±° ë¨¸ì„ã…‹ã…‹ã…‹ã…‹ã…‹ ë‚˜ë„ ë³´ë‚´ì¤˜ [/TGT]'}"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    }
  ]
}